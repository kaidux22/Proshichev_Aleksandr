# -*- coding: utf-8 -*-
"""lab2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1HNhKhCD62_Qp2QYw8V3_iP4Q2_Sefb4x

# Лабораторная работа №2: Классические методы математической статистики
Выполнил студент гр. 1384 Прошичев Александр. Вариант №12

## Цель работы
Цель:\
Научится применять методы математической статистики для визуализации и анализа полученных данных. Сформировать навыки реализации методов с помощью прикладных программных пакетов.

## Основные теоретические положения



---

###Выборочные числовые характеристики:


Математическое ожидание\
 $\bar{X}=\frac{1}{n}\sum_{i=1}^{n}X_{i}$

Дисперсия\
 $S^{2}=\frac{1}{n}\sum_{i=1}^{n}\left( X_{i}-\overline{X} \right)^{2}=\overline{X^{2}}-\overline{X}^{2}$

Коэффициент асимметрии\
 $\widehat{ASI}= \displaystyle \frac{\left(\frac{1}{n}\sum_{i=1}^{n}\left( X_{i}-\overline{X} \right)^{3} \right)}{S^{3}}$

Коэффициент эксцесса\
 $\widehat{EXC}= \displaystyle \frac{\frac{1}{n}\sum_{i=1}^{n}\left( X_{i}-\overline{X}^{4} \right)}{S^{4}}-3$



---



###Оценка Максимального Правдоподобия (ОМП):

Если $X_{1},...,X_{n}$-выборка из распределения с плотностью распределения $p_{\theta}, \theta\in \Theta$, то функция правдоподобия $L(\vec{X},\theta)= \displaystyle \prod_{i=1}^{n}p_{\theta}(X_{i}).\ $ Логарифм функции правдоподобия представляется в виде $LL(\vec{X},\theta)=\ln L(\vec{X},\theta)$.
В силу монотонности логарифма задача максимизации функции правдоподобия сводится к задаче максимизации ее логарифма по всем параметрам $\theta\in \Theta$

Если $\theta$ - d-мерный параметр и $P_{\theta}$ дифференцируема по $\theta$, то для нахождения максимума надо найти решения системы уравнений: $\frac{\partial }{\partial \theta}LL(\vec{X},\theta)=0, i=1...d$


---


###Оценка метода моментов (ОММ)

Пусть $X_{1}...X_{n}$-выбока из распределения $P_{\theta}, \theta=(\theta_{1},...,\theta_{d})$

$\exists \mu_{k}(\theta)=\mathbb{E}X^{k}_{1}, k=1...d$

Если существуется единственное решение $\widetilde{\theta}(X)$ системы уравнений: $\widehat{\mu^{k}}(\widetilde{\theta})=\mu_{k}(\theta), k=1...d$, где $\widetilde{\theta}(X)=\frac{1}{n}\sum_{i=1}^{n}X^{k}_{i}$-выборочный момент k-го порядка, то $\widetilde{\theta}(X)$ называется оценкой по методу моментов



---


###Асимптотический доверительный интервал

На базе Асимптотической нормальности оценки $\widehat{\theta}$

Асимптотическая нормальность $\displaystyle \sqrt{n}\left( \widehat{\theta}(\vec{X})-\theta)\right)\sim \mathcal{N}\left(0,\sigma^{2}(\theta)\right)$

Тогда $\displaystyle \sqrt{n}\frac{\widehat{\theta}(\vec{X})-\theta}{\sigma\left(\widehat{\theta}(\vec{X})\right)}$    

Выбираем $\displaystyle X_{\alpha}: \Phi(X_{\alpha})=1-\frac{\alpha}{2}$

Асимптотический доверительный интервал  $\displaystyle \left[ \widehat{\theta}(\vec{X})-\frac{X_{\alpha}\cdot \sigma\left( \widehat{\theta}(\vec{X}) \right)}{\sqrt{n}}; \widehat{\theta}(\vec{X})+\frac{X_{\alpha}\cdot \sigma\left( \widehat{\theta}(\vec{X}) \right)}{\sqrt{n}}\right]$

На базе ОМП. Пусть $\widehat{\theta}(\vec{X})$-ОМП

При выполнении опр.условий регулярности: $\sqrt{n}\left( \widehat{\theta}(\vec{X})-\theta)\right)\sim \mathcal{N}\left(0,\frac{1}{I(\theta)}\right), I(\theta)=-\mathbb{E}\left( \frac{\partial^{2} LL}{\partial \theta^{2}} \right)$-информация Фишера

Тогда $\sqrt{n\cdot I\left( \widehat{\theta}(\vec{X}) \right)}\cdot \left( \widehat{\theta}(\vec{X})-\theta \right)\sim \mathcal{N}(0,1)$

Выбираем $X_{\alpha}: \Phi(X_{\alpha})=1-\frac{\alpha}{2}$

Асимптотический доверительный интервал  $\left[ \widehat{\theta}(\vec{X})-\frac{X_{\alpha}}{\sqrt{n\cdot I\left( \widehat{\theta}(\vec{X}) \right)}};\widehat{\theta}(\vec{X})+\frac{X_{\alpha}}{\sqrt{n\cdot I\left( \widehat{\theta}(\vec{X}) \right)}} \right]$



---



###Критерий $\chi^2$ для проверки гипотез

Основан на справнении теоритической плотности распределения и гистограммы, либо теоритической вероятностной меры и полигона частот.

Разобъем множество значений сл. вел. X на $N$ интервалов $I_{1}...I_{N}:$ $I_{i} = (a_{i-1}, a_i], i = 1...N$. данные интервалы не пересекаются и покрывают всё множество возможных значений сл. вел. X.

Обозначим через $p_{i}$ теоритическую вероятность попадания случайной величины X в интервал $I_{i}$, при условии, что справедлива $H_{0}$.

$p_{i} = P(X \in I_{i}|H_{0})$

Через $n_{i}$ обозначим число наблюдений нашей выборки, попавших в соответветствующий интервал $I_{i}$.

$n_{i} = \nu(x_{j} \in I_{i})$

Статистика критерия основана на сравнении относительной частоты и теоритической.

$\chi^{2} = \sum \limits_{i=1}^{N} \frac{n}{p_{i}} \bigg ( \frac{n_{i}}{n} - p_{i} \bigg )^{2} = \sum \limits_{i=1}^{N} \frac{(n_{i} - p_{i} n)^{2}}{n p_{i}} \sim \chi^{2}_{N-1}$

6. Теорема Колмогорова

$D_{n}(\vec{X}) = \overset{}{\underset{X \in \mathbb R}{sup}} |F_{0}(X_{i}) - F_{n}(X_{i})|$

Если гипотеза $H_{0}$ верна, и $F_{0}(X)$ - непрерывная ф-я на $\mathbb R$, тогда имеет место сходимость

$P(\sqrt{n} D_{n}(\vec{X}) < z) \xrightarrow[n \rightarrow \infty]{} K(z)$, где

$K(z)=1-\alpha$ - ф-я распределения Колмогорова.

Если $D_{n} \lt z$, то гипотезу принимаем.

Если $D_{n} \gt z$, то гипотезу отвергаем.



---



###Наиболее мощный критерий простой гипотезы.

Для основной гипотезы $H_{0}: \theta=\theta_{0}$ и альтернативной гипотезы $H_{1}: \theta=\theta_{1}$, где $\theta_{0}$ и $\theta_{1}$ - фиксированные параметры, мы можем построить статистику правдоподобия:

$LR(\vec{X},\theta_{1},\theta_{0})=\frac{L(\vec{X},\theta_{1})}{L(\vec{X},\theta_{0})} $- статистика отношений правдоподобия

где $L(\vec{X},\theta_{1})$ - функция правдоподобия для альтернативной гипотезы, а $L(\vec{X}\theta_{0})$ - функция правдоподобия для основной гипотезы.

Наиболее мощный критерий:

$\phi(\vec X) = \begin{cases}
  0, LR(\vec{X},\theta_{1},\theta_{0}) < C \\
  p, LR(\vec{X},\theta_{1},\theta_{0}) = C \\
  1, LR(\vec{X},\theta_{1},\theta_{0}) > C
\end{cases} $



---

## Постановка задачи

Перед выполнение работы подключим необходимые библиотеки.
"""

from mpl_toolkits import mplot3d
import numpy as np
import matplotlib.pyplot as plt
import scipy.stats as sps
import scipy.optimize as spo

"""## Выполнение работы
### **1 задание**.
#### **Пункт А**. Построить вариационный ряд, эмпирическую функцию распределения и гистограмму частот.
Первоначальная выборка:
$ \begin{array}{|c|c|} \hline X_{i} & 8 & 3 & 6 & 5 & 3 & 1 & 2 & 4 & 2 & 8 & 2 & 4 & 1 & 3 & 2 & 1 & 13 & 2 & 4 & 2 & 3 & 9 & 2 & 4 & 6 & 1 & 9 & 2 & 4 & 1 & 3 & 6 & 5 & 3 & 5 & 3 & 4 & 6 & 4 & 6 & 2 & 2 & 4 & 8 & 5 & 2 & 3 & 1 & 3 & 6 \\ \hline
\end{array} $

Вариационный ряд:
$ \begin{array}{|c|c|} \hline X_{i} & 1 & 1 & 1 & 1 & 1 & 1 & 2 & 2 & 2 & 2 & 2 & 2 & 2 & 2 & 2 & 2 & 2 & 3 & 3 & 3 & 3 & 3 & 3 & 3 & 3 & 3 & 4 & 4 & 4 & 4 & 4 & 4 & 4 & 4 & 5 & 5 & 5 & 5 & 6 & 6 & 6 & 6 & 6 & 6 & 8 & 8 & 8 & 9 & 9 & 13 \\ \hline
\end{array} $

Построим эмпирическую функию распределения $F_n(x) = \frac{1}{n} \displaystyle\sum_{i=1}^{n} \chi \{ X_i < x \}$ и гистограмму частот $ H(x) = \frac{\nu(x)}{nh} $ при $h = 1$.

Для этого составим таблицу частот \
$ \begin{array}{|c|c|} \hline X_{(i)} & 1 & 2 & 3 & 4 & 5 & 6 & 8 & 9 & 13 \\ \hline \nu(x = X_{(i)})  & 6 & 11 & 9 & 8 & 4 & 6 & 3 & 2 & 1  \\ \hline
\end{array} $
"""

def VarRow(x):
  cnts = [[1, 6], [2, 11], [3, 9], [4, 8], [5, 4], [6, 6], [8, 3], [9, 2], [13, 1]]

  sm = 0
  for pair in cnts:
    if pair[0] >= x:
      return sm
    sm += pair[1]
  return sm

x = np.arange(0, 14, 0.01)
y = [VarRow(elem) / 50 for elem in x]



plt.title('График эмпирической функции распределения')
plt.xlabel('x', fontsize=12)
plt.ylabel('Fn(x)', fontsize=12)
plt.plot(x, y, 'red')
plt.show()

def Hist(x):
  cnts = [[1, 6], [2, 11], [3, 9], [4, 8], [5, 4], [6, 6], [8, 3], [9, 2], [13, 1]]

  if x < cnts[0][0]:
    return 0

  for i in range(len(cnts)):
    if x <= cnts[i][0] and (cnts[i][0] - x) < 1:
      return cnts[i][1]
  return 0

x = np.arange(1, 14, 1)
y = [Hist(elem) / 50 for elem in x]



plt.title('Гистограмма частот')
plt.xlabel('x', fontsize=12)
plt.ylabel('H(x)', fontsize=12)
plt.bar(x, y, width=1, align='edge', color='orange', edgecolor='black')
plt.show()

"""#### **Пункт B**. Вычислить выборочные аналоги следующих числовых характеристик:
(i) математического ожидания; (ii) дисперсии; (iii) СКО; (iv) медианы; (v) асимметрии; (vi) эксцесса; (vii) вероятности $ \mathbb{P}(X \in [2.4, 5.6]) $

i) $ \bar{X} = \frac{\large{1}}{\large{50}} \displaystyle\sum_{i=1}^{50}X_i $ - выборочное среднее

ii) $ S^2  = \frac{\large{1}}{\large{50}} \displaystyle\sum_{i=1}^{50} \left(X_i^2 - \left(\bar{X}\right)^2 \right)$ - выборочная дисперсия

iii) $ S $ - среднее квадратичное отклонение

iv) $ z_{50, \frac{1}{2}} = \left[ X_{ \left( 25 \right)},  X_{ \left( 26 \right)} \right)$ - выборочная медиана

v) $ \widehat{\small ASI} = \frac{ \frac{\Large{1}}{\Large{50}} \displaystyle\sum^{50}_{i=1} \left( X_i - \bar{X} \right)^3}{\large{S^3}}$ - выборочная ассиметрия

vi) $ \widehat{\small EXC} = \frac{ \frac{\Large{1}}{\Large{50}} \displaystyle\sum^{50}_{i=1} \left( X_i - \bar{X} \right)^4}{\large{S^4}} - 3$ - выборочный коэффициент эксцесса

vii) $ \mathbb{P}(X \in [2.4, 5.6]) = F_n(5.6) - F_n(2.4) $
"""

arr = np.array([1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 8, 8, 8, 9, 9, 13])

X = np.mean(arr)
S2 = np.var(arr)
S = np.std(arr)
z = np.median(arr)
asi = np.sum((arr - X)**3) / (50 * S ** 3)
exc = np.sum((arr - X)**4) / (50 * S ** 4) - 3

print("Выборочное среднее =", round(X, 3))
print("Выборочная дисперсия =", round(S2, 3))
print("СКО =", round(S, 3))
print("Выборочная медиана равна =", round(z, 3))
print("Выборочная ассиметрия равна =", round(asi, 3))
print("Выборочный коэффициент эксцесса =", round(exc, 3))
print("Выборочная вероятность попадения в промежуток [2.4, 5.6] =", (VarRow(5.6) - VarRow(2.4)) / 50)

"""#### **Пункт C.** В предположении, что исходные наблюдения являются выборкой из распределения Пуассона, построить оценку максимального правдоподобия параметра  , а также оценку   по методу моментов. Найти смещение оценок.

Распределение Пуассона: $ \xi \sim Pois(\lambda) \implies P_{\lambda}(\xi = k) = \frac{\large{\lambda^k}}{\large{k!}} e^{-\lambda} $ при $ \lambda \in (0, +\infty)$ \
$ supp \xi = \mathbb{Z}; $ $ E_\theta \xi = D_\theta \xi = \lambda $ \
\
\
Расчёт ОМП \
$ L(\vec{X}, \theta) = \small \displaystyle \prod_{i = 1}^{n} \frac{\lambda^{X_i}}{X_i!} e^{- \lambda} = \frac{\large \lambda^{n \bar{X}}}{\displaystyle \prod_{i = 1}^{n} \left( X_i! \right)} e^{- \lambda n}$ \
$ LL(\vec{X}, \theta) = ln\lambda \displaystyle \sum_{i=1}^{n} X_i - \displaystyle \sum_{i=1}^{n} ln \left( X_i \right) - \lambda n$ \
$ \frac{\large \partial LL(\vec{X}, \theta)}{\large \partial \lambda} = \frac{\displaystyle \sum_{i=1}^{n} X_i}{\large \lambda} - n = 0 \implies \hat{\lambda} = \frac{\displaystyle \sum_{i=1}^{n} X_i}{\large n} = \bar{X} = 3.96$ \
\
\
Расчёт ОММ \
$ EX_1 = \lambda $\
$ M_1 = \bar{X} $ \
$ \hat{\lambda} = \bar{X} = 3.96$\
\
\
Оценки совпадают. Посчитаем смещещение оценок.\
$ E \hat{\lambda} = E \bar{X} = \frac{1}{n} E \displaystyle \sum_{i=1}^{n}{X_i} = \frac{1}{n} \displaystyle \sum_{i=1}^{n} E {X_i} = \frac{1}{n} \displaystyle \sum_{i=1}^{n} \lambda  = \frac{\lambda n}{n} = \lambda $\
 Тогда полученные оценки являются несмещёнными.

#### **Пункт D.** Построить асимптотический доверительный интервал уровня значимости $ \alpha_1 $ для параметра $ \lambda $ на базе оценки максимального правдоподобия.

**1 способ.** На основе ОМП. \
$ I_n(\lambda) = -E \frac{\large \partial^2 LL(\vec{X}, \theta)}{\large \partial \lambda^2}$ \
$ \frac{\large \partial^2 LL(\vec{X}, \theta)}{\large \partial \lambda^2} = - \frac{\displaystyle \sum_{i=1}^{n} X_i}{\large \lambda^2} = - \large \frac{n \bar{X}}{\lambda^2}$ \
Тогда $ -E \frac{\large \partial^2 LL(\vec{X}, \theta)}{\large \partial \lambda^2} = E \large \frac{n \bar{X}}{\lambda^2} = \frac{1}{\lambda^2} E \small \displaystyle \sum_{i=1}^{n} X_i = \frac{1}{\lambda^2} \displaystyle \sum_{i=1}^{n} E \small X_i = \frac{n \lambda}{\lambda^2} = \frac{n}{\lambda}$ \
$ I(\lambda) = \frac{1}{\lambda}$

$ x_{a} : Ф(x_a) = 1 - \frac{\large \alpha_1}{\large 2} = 1 - 0.01 = 0.99$
"""

fx = 0.99
x_a = sps.norm.ppf(fx)

print("Квантиль x_a =", round(x_a, 3))
print("Функция нормального распределения Ф(x_a) =", sps.norm.cdf(x_a))

"""$ \lambda \in  \left[ \bar{X} - \frac{\large x_{\alpha} \sqrt{\bar{X}}}{\large \sqrt{n}}; \bar{X} + \frac{\large x_{\alpha} \sqrt{\bar{X}}}{\large \sqrt{n}} \right] = [3.305, 4.615]$ \
\
**2 способ.** На основе ЦПТ. \
$ \sqrt{n} \frac{\large \hat{\lambda} - \lambda}{\large \sqrt{\lambda}} \sim \mathcal{N}(0, 1)$ \
$ x_{\alpha} : Ф(x_a) = 1 - \frac{\large \alpha_1}{\large 2} = 1 - 0.01 = 0.99$ \
$ x_{\alpha} = 2.326 $\
$ P_{\lambda} \left( \sqrt{n} \frac{\large \left| \hat{\lambda} - \lambda \right|}{\sqrt{\large \lambda}} \leq x_{\alpha}\right) = 1 - \alpha_1 = 0.98 $ \
\
**2.1)** $ P_{\lambda} \left( \sqrt{n} \frac{\large \left| \bar{X} - \lambda \right|}{\sqrt{\large \lambda}} \leq x_{\alpha}\right) = 0.98 $ \
$ \left| \bar{X} - \lambda \right| \leq \frac{\large x_{\alpha} \sqrt{\lambda}}{\large \sqrt{n}} \implies \left( \bar{X} - \lambda \right) ^ 2 \leq \frac {\large x_{\alpha}^2 \lambda}{\large n} \implies n \left( \bar{X} \right)^2 - 2n \lambda \bar{X} + n \lambda^2 - x_{\alpha}^2 \lambda \leq 0 \implies n \lambda^2 - \lambda \left( 2n \bar{X} + x_{\alpha}^2 \right) + n \left( \bar{X} \right)^2 \leq 0 $ \
$ D = \left( 2n \bar{X} + x_{\alpha}^2 \right) ^ 2 - 4 n^2 \left( \bar{X} \right)^2 = 4315.509 $ \
$ \lambda_1 = \frac{\large 2n \bar{X} + x_{\alpha}^2 - \sqrt{D}}{\large 2n} = 3.357 $ \
$ \lambda_2 = \frac{\large 2n \bar{X} + x_{\alpha}^2 + \sqrt{D}}{\large 2n} = 4.671 $ \
$ \lambda \in \left[ 3.357, 4.671 \right] $ \
\
**2.2)** $ P_{\lambda} \left( \sqrt{n} \frac{\large \left| \bar{X} - \lambda \right|}{\sqrt{\large \bar{X}}} \leq x_{\alpha}\right) = 0.98 $ \
$ -x_{\alpha} \leq \sqrt{n} \frac{\large \bar{X} - \lambda}{\sqrt{\large \bar{X}}} \leq x_{\alpha} \implies \bar{X} - \frac{\large x_{\alpha} \sqrt{\bar{X}}}{\large \sqrt{n}} \leq \lambda \leq \bar{X} + \frac{\large x_{\alpha} \sqrt{\bar{X}}}{\large \sqrt{n}}$ \
$ \lambda \in \left[ 3.305, 4.615 \right] $ \
\
**2.3)** $ P_{\lambda} \left( \sqrt{n} \frac{\large \left| \bar{X} - \lambda \right|}{\large S} \leq x_{\alpha}\right) = 0.98 $ \
$ -x_{\alpha} \leq \sqrt{n} \frac{\large \bar{X} - \lambda}{\large S} \leq x_{\alpha} \implies \bar{X} - \frac{\large x_{\alpha} S}{\large \sqrt{n}} \leq \lambda \leq \bar{X} + \frac{\large x_{\alpha} S}{\large \sqrt{n}}$ \
$ \lambda \in \left[ 3.136, 4.784 \right] $

#### **Пункт E.** Используя гистограмму частот, построить критерий значимости $ \chi^2 $ проверки простой гипотезы согласия с распределением Пуассона с параметром  $\lambda_0= 5.00$. Проверить гипотезу на уровне значимости $\alpha_1 = 0.02$. Вычислить наибольшее значение уровня значимости, на котором ещё нет оснований отвергнуть данную гипотезу.

Таблица частот \
$ \begin{array}{|c|c|} \hline X_{(i)} & 1 & 2 & 3 & 4 & 5 & 6 & 8 & 9 & 13 \\ \hline \nu(x = X_{(i)})  & 6 & 11 & 9 & 8 & 4 & 6 & 3 & 2 & 1  \\ \hline
\end{array} $

Сгруппируем данные по интевалам.\
$ \begin{array}{|c|c|} \hline j & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9\\ \hline I_j & (-\infty, 1] & (1, 2] & (2, 3] & (3, 4] & (4, 5] & (5, 6] & (6, 8] & (8, 9] & (9, +\infty) \\ \hline \nu_j  & 6 & 11 & 9 & 8 & 4 & 6 & 3 & 2 & 1  \\ \hline
\end{array} $ \
\
$ \measuredangle$ Основную гипотезу $H_0: P_{\lambda}(\xi \in I_j) = P_{\lambda_0}(\xi \in I_j)$ для всех $j = 1...9$ \
и альтернативную - $ H_А: {\exists j}$ $P_{\lambda}(I_j) \neq P_{\lambda_0}(I_j)$ при $j \in 1...9$ \
Гипотеза $ H_0 $ является более слабой по отношению к предложенной в условии, поэтому опровержение $ H_0 $ влечёт за собой опровержение и заданной гипотезы. \
\
Вычислим результаты и структурируем их в таблице \
$ \begin{array}{|c|c|} \hline I_j & \nu_j & p_{j0} & \frac{\large \left( \nu -np_{j0} \right)^2}{\large np_{j0}}\\ \hline (-\infty, 1] & 6 & 0.0404 & 7.842 \\ \hline (1, 2] & 11 & 0.0842 &  10.951\\ \hline (2, 3] & 9 & 0.1404 & 0.558\\ \hline (3, 4] & 8 & 0.1755 & 0.068 \\ \hline (4, 5] & 4 & 0.1755 & 2.598 \\ \hline (5, 6] & 6 & 0.1462 & 0.235 \\ \hline (6, 8] & 3 & 0.1697 & 3.546\\ \hline (8, 9] & 2 & 0.0363 & 0.019 \\ \hline (9, +\infty) & 1 & 0.0318 & 0.219 \\ \hline \end{array} $ \
\
$ \chi^2 = 26.036$\
\
Расчёты получены в результате следующей программы
"""

arr = [1, 2, 3, 4, 5, 6, 8, 9]
res = [0] * (len(arr) + 1)

#Вычисление p_j0
res[0] = round(sps.poisson.cdf(1, 5),4)
sm = res[0]

for i in range(1, len(arr)):
  res[i] = round(sps.poisson.cdf(arr[i], 5) - sps.poisson.cdf(arr[i - 1], 5), 4)
  sm += res[i]
res[len(arr)] = round(1 - sps.poisson.cdf(9, 5), 4)
print("p_j0 =", res)
print("Проверка результата. Сумма p_j0 =", sm + res[len(arr)])

#Вычисление X^2
v = [6, 11, 9, 8, 4, 6, 3, 2, 1]
ans = [round((v[i] - 50 * res[i]) ** 2 / (50 * res[i]), 3) for i in range(len(v))]
print("Последний столбец =", ans)
print("X^2 =", round(sum(ans), 3))

"""$ x_{a} : \mathcal{K}_{r-1}(x_a) = \mathcal{K}_8(x_a) = 1 - \alpha_1 = 1 - 0.02 = 0.98$"""

func = sps.chi2(8)
fx = 0.98
x_a = func.ppf(fx)

print("Квантиль x_a =", round(x_a, 3))
print("Функция распределения K_8(x_a) =", func.cdf(x_a))

"""Т.к. $\chi^2 > x_\alpha$ , то гипотеза отвергается\
Найдём наибольшее значение уровня значимости, на котором нет оснований отвергнуть гипотезу. Пусть $\mathbb{P}(\chi^2 \leq x_\alpha) = 0$\
Тогда $ \chi^2 \leq x_\alpha \implies \chi^2 \leq \mathcal{K}_8^{-1}(1 - \alpha_1) \implies \mathcal{K}_8(\chi^2) \leq 1 - \alpha_1 \implies \alpha_1 \leq 1 - \mathcal{K}_8(\chi^2)$

"""

x2 = 26.036
print("Наибольшее значение уровня значимости =", round(1 - sps.chi2.cdf(x2, 8), 5))

"""####**Пункт F.** Построить критерий значимости $\chi^2$ проверки сложной гипотезы согласия с распределением Пуассона. Проверить гипотезу на уровне значимости $\alpha_1=0.02$. Вычислить наибольшее значение уровня значимости, на котором ещё нет оснований отвергнуть данную гипотезу.

Проверим сложную гипотезу $ H_0 : X_1... X_n \sim Pois(\lambda) $ \
Альтернативой ей будет служить $ H_A : X_1 ...X_n$ не распределена, как $Pois(\lambda)$

Таблица интервалов\
$ \begin{array}{|c|c|} \hline j & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9\\ \hline I_j & (-\infty, 1] & (1, 2] & (2, 3] & (3, 4] & (4, 5] & (5, 6] & (6, 8] & (8, 9] & (9, +\infty) \\ \hline \nu_j  & 6 & 11 & 9 & 8 & 4 & 6 & 3 & 2 & 1  \\ \hline
\end{array} $ \

Т.к. гипотеза сложная, то статистикой критерия возьмём $ \tilde{\chi^2} = min_\lambda \chi^2(\lambda) = min_\lambda \displaystyle \sum_{j=1}^{9} \frac{\large \left( \nu_j -np_{j0}(\lambda) \right)^2}{\large np_{j0}(\lambda)} \underset{n \rightarrow \infty}{\implies} \chi^2_{7}$. Размерность $\chi^2$-распределения вычисляется по формуле $ r - d - 1 $, где $r$ - количество интервалов, а $d = dim(\Theta_0)$
"""

def CuclSum(h):
  if h == 0:
    return 10**6

  arr = [1, 2, 3, 4, 5, 6, 8, 9]
  res = [0] * (len(arr) + 1)

  #Вычисление p_j0
  res[0] = sps.poisson.cdf(1, h)
  sm = res[0]

  for i in range(1, len(arr)):
    res[i] = sps.poisson.cdf(arr[i], h) - sps.poisson.cdf(arr[i - 1], h)
  res[len(arr)] = 1 - sps.poisson.cdf(9, h)

  #Вычисление X^2
  v = [6, 11, 9, 8, 4, 6, 3, 2, 1]
  ans = [(v[i] - 50 * res[i]) ** 2 / (50 * res[i]) for i in range(len(v))]
  return sum(ans)

result = spo.minimize_scalar(CuclSum)
print("Значение X^2 =", round(result.fun, 3), "при значении параметра =", round(result.x, 3))

"""$ x_{a} : \mathcal{K}_{r-d-1}(x_a) = \mathcal{K}_7(x_a) = 1 - \alpha_1 = 1 - 0.02 = 0.98$"""

fx = 0.98
x_a = sps.chi2.ppf(fx, 7)

print("Квантиль x_a =", round(x_a, 3))
print("Функция распределения K_8(x_a) =", sps.chi2.cdf(x_a, 7))

"""Т.к. $\chi^2 < x_\alpha$ , то гипотеза принимается\
Найдём наибольшее значение уровня значимости, на котором нет оснований отвергнуть гипотезу. Пусть $\mathbb{P}(\chi^2 \leq x_\alpha) = 0$\
Тогда $ \chi^2 \leq x_\alpha \implies \chi^2 \leq \mathcal{K}_7^{-1}(1 - \alpha_1) \implies \mathcal{K}_7(\chi^2) \leq 1 - \alpha_1 \implies \alpha_1 \leq 1 - \mathcal{K}_7(\chi^2)$

"""

x_a = 8.697
print("Наибольшее значение уровня значимости =", round(1 - sps.chi2.cdf(x_a, 7), 3))

"""#### **Пункт G.** Построить наиболее мощный критерий проверки простой гипотезы пуассоновости с параметром $ \lambda_0 = 5.00 $ при альтернативе пуассоновости с параметром $ \lambda_1 = 4.00 $. Проверить гипотезу на уровне значимости $\alpha_1 = 0.02$. Что получится, если поменять местами основную и альтернативную гипотезы?

Рассмотрим две гипотезы. \
Основная гипотеза $H_0 : X_1...X_n \sim Pois(\lambda_0)$\
Альтернативная гипотеза $H_А : X_1...X_n \sim Pois(\lambda_1)$\
\
По лемме Неймана-Пирса\
$\varphi \left( \vec{X} \right) = \begin{cases} 0, \quad LR \left( \vec{X}, \lambda_1, \lambda_0 \right) < x_\alpha \\ p, \quad LR \left( \vec{X}, \lambda_1, \lambda_0 \right) = x_\alpha \\ 1, \quad LR \left( \vec{X}, \lambda_1, \lambda_0 \right) > x_\alpha \end{cases}$, где $LR \left( \vec{X}, \lambda_1, \lambda_0 \right) = \frac{\large L \left( \vec{X}, \lambda_1 \right)}{\large L \left( \vec{X}, \lambda_0 \right)}$

Из пункта C\
$ L(\vec{X}, \lambda_1) = \frac{\LARGE \lambda_1^{n \bar{X}}}{\small \displaystyle \prod_{i = 1}^{n} \left( X_i! \right)} e^{\Large - \lambda_1 n} = \frac{\Large 4^{\LARGE n \bar{X}}}{\small \displaystyle \prod_{i = 1}^{n} \left( X_i! \right)} e^{\Large - 200}$\
$ L(\vec{X}, \lambda_0) = \frac{\LARGE \lambda_0^{n \bar{X}}}{\small \displaystyle \prod_{i = 1}^{n} \left( X_i! \right)} e^{\Large - \lambda_0 n} = \frac{\Large 5^{\LARGE n \bar{X}}}{\small \displaystyle \prod_{i = 1}^{n} \left( X_i! \right)} e^{\Large - 250}$\
Тогда $\frac{\large L \left( \vec{X}, \lambda_1 \right)}{\large L \left( \vec{X}, \lambda_0 \right)} = \left( \frac{\Large 4}{\Large 5} \right) ^{\Large n \bar{X}} e^{50} $\
$T = \bar{X}$ - МДС\
\
Пусть $ LR \left( \vec{X}, \lambda_1, \lambda_0 \right) > x_\alpha $ \
$ \left( \frac{\Large 4}{\Large 5} \right) ^{\Large n \bar{X}} e^{50} > x_\alpha $\
\
$  n \bar{X} \ ln\left( \frac{\Large 4}{\Large 5} \right) + 50 > lnx_\alpha $\
\
$ \bar{X} \  < x_a^* = (\frac{\large lnx_\alpha}{50} - 1) \frac{1}{ln\left( \frac{\Large 4}{\Large 5} \right)} $\
\
$\varphi \left( \vec{X} \right) = \begin{cases} 0, \quad \bar{X} >  x_\alpha^* \\ p, \quad \bar{X} =  x_\alpha^* \\ 1, \quad \bar{X} <  x_\alpha^* \end{cases}$
\
\
Вычислим $ x_\alpha^*$ и $ p $, учитывая, что выборка из Пуассоновского распределения. \
$ E_{\lambda_0} \varphi(\vec{X}) = \mathbb{P_{\lambda_0}} \left( \bar{X} < x_a^* \right) + p \ \mathbb{P_{\lambda_0}} \left( \bar{X} = x_a^* \right) = \alpha_1$\
$ \mathbb{P_{\lambda_0}} \left( \bar{X} \leq x_a^* \right) = \mathbb{P_{n\lambda_0}} \left( n\bar{X} \leq nx_a^* \right) = \small \displaystyle \sum_{i=0}^{\large [nx_a^*]} P_{n\lambda_0}(\xi = i) = \small \displaystyle \sum_{i=0}^{\large [nx_a^*]} \frac{\large{(n\lambda_0)^i}}{\large{i!}} e^{-n\lambda_0}$\
\
Подбираем $x_\alpha$\
$ \small \displaystyle \sum_{i=0}^{\large [nx_a^*] - 1} \frac{\large{(n\lambda_0)^i}}{\large{i!}} e^{-n\lambda_0} \leq \alpha_1 < \small \displaystyle \sum_{i=0}^{\large [nx_a^*]} \frac{\large{(n\lambda_0)^i}}{\large{i!}} e^{-n\lambda_0}$\. Тогда $ nx_\alpha^* = 281 \implies x_\alpha^* = 4.36 $\
\
Считаем p\
$ p = \frac{\large \alpha_1 - \small \displaystyle \sum_{i=1}^{\large [nx_a^*] - 1} \frac{\large{(n\lambda_0)^i}}{\large{i!}} e^{-n\lambda_0}}{\Large \frac{{(n\lambda_0)^{[nx_a^*]}}}{{[nx_a^*]!}} e^{-n\lambda_0}} = 0.559$\
\
Расчёты были воспроизведены в программе ниже


"""

func = sps.poisson(50 * 5)
a = 0.02
c = 1
while True:
  if sps.poisson.cdf(c - 1, 250) <= a and a < sps.poisson.cdf(c, 250):
    break
  c += 1

p = (a - sps.poisson.cdf(c - 1, 250))/(sps.poisson.cdf(c, 250) - sps.poisson.cdf(c - 1, 250))

print("Полученная константа", c)
print("Полученная вероятность", round(p, 3))

"""Получен наиболее мощный критерий\
$\varphi \left( \vec{X} \right) = \begin{cases} 0, \quad \bar{X} >  4.36 \\ 0.559, \quad \bar{X} =  4.36* \\ 1, \quad \bar{X} <  4.36 \end{cases}$\
\
Т.к. $ \bar{X} = 3.96 < 4.36 \implies H_0$ отвергаем.\
\
\
Поменяем гипотезы местами.\
Основная гипотеза $H_0 : X_1...X_n \sim Pois(\lambda_1)$\
Альтернативная гипотеза $H_А : X_1...X_n \sim Pois(\lambda_0)$\
\
По лемме Неймана-Пирса\
$\varphi \left( \vec{X} \right) = \begin{cases} 0, \quad LR \left( \vec{X}, \lambda_0, \lambda_1 \right) < x_\alpha \\ p, \quad LR \left( \vec{X}, \lambda_0, \lambda_1 \right) = x_\alpha \\ 1, \quad LR \left( \vec{X}, \lambda_0, \lambda_1 \right) > x_\alpha \end{cases}$, где $LR \left( \vec{X}, \lambda_0, \lambda_1 \right) = \frac{\large L \left( \vec{X}, \lambda_0 \right)}{\large L \left( \vec{X}, \lambda_1 \right)}$

Из пункта C\
$ L(\vec{X}, \lambda_1) = \frac{\LARGE \lambda_1^{n \bar{X}}}{\small \displaystyle \prod_{i = 1}^{n} \left( X_i! \right)} e^{\Large - \lambda_1 n} = \frac{\Large 4^{\LARGE n \bar{X}}}{\small \displaystyle \prod_{i = 1}^{n} \left( X_i! \right)} e^{\Large - 200}$\
$ L(\vec{X}, \lambda_0) = \frac{\LARGE \lambda_0^{n \bar{X}}}{\small \displaystyle \prod_{i = 1}^{n} \left( X_i! \right)} e^{\Large - \lambda_0 n} = \frac{\Large 5^{\LARGE n \bar{X}}}{\small \displaystyle \prod_{i = 1}^{n} \left( X_i! \right)} e^{\Large - 250}$\
Тогда $\frac{\large L \left( \vec{X}, \lambda_0 \right)}{\large L \left( \vec{X}, \lambda_1 \right)} = \left( \frac{\Large 5}{\Large 4} \right) ^{\Large n \bar{X}} e^{-50} $\
$T = \bar{X}$ - МДС\
\
Пусть $ LR \left( \vec{X}, \lambda_0, \lambda_1 \right) > x_\alpha $ \
$ \left( \frac{\Large 5}{\Large 4} \right) ^{\Large n \bar{X}} e^{-50} > x_\alpha $\
\
$  n \bar{X} \ ln\left( \frac{\Large 5}{\Large 4} \right) - 50 > lnx_\alpha $\
\
$ \bar{X} \  > x_a^* = (\frac{\large lnx_\alpha}{50} + 1) \frac{1}{ln\left( \frac{\Large 5}{\Large 4} \right)} $\
\
$\varphi \left( \vec{X} \right) = \begin{cases} 0, \quad \bar{X} <  x_\alpha^* \\ p, \quad \bar{X} =  x_\alpha^* \\ 1, \quad \bar{X} >  x_\alpha^* \end{cases}$
\
\
Вычислим $ x_\alpha^*$ и $ p $, учитывая, что выборка из Пуассоновского распределения. \
$ E_{\lambda_1} \varphi(\vec{X}) = \mathbb{P_{\lambda_1}} \left( \bar{X} > x_a^* \right) + p \ \mathbb{P_{\lambda_1}} \left( \bar{X} = x_a^* \right) = \alpha_1$\
\
Подбираем $x_\alpha$\
$ \mathbb{P_{\lambda_1}} \left( \bar{X} > x_a^* \right) = 1 - \mathbb{P_{n\lambda_1}} \left( n\bar{X} \leq nx_a^* \right) = 1 - \small \displaystyle \sum_{i=0}^{\large [nx_a^*]} P_{n\lambda_1}(\xi = i) = 1 - \small \displaystyle \sum_{i=0}^{\large [nx_a^*]} \frac{\large{(n\lambda_1)^i}}{\large{i!}} e^{-n\lambda_1} < \alpha_1$\
Тогда $ nx_\alpha^* = 230 \implies x_\alpha^* = 4.6 $\
\
$ p = \frac{\large \alpha_1 - 1 + \small \displaystyle \sum_{i=0}^{\large [nx_a^*]} \frac{\large{(n\lambda_1)^i}}{\large{i!}} e^{-n\lambda_1}}{\Large \frac{{(n\lambda_0)^{[nx_a^*]}}}{{[nx_a^*]!}} e^{-n\lambda_0}} = 0.927 $\
\
Расчёты были воспроизведены в программе ниже


"""

a = 0.02
c = 1
while True:
  if 1 - sps.poisson.cdf(c, 200) < a:
    break
  c += 1

p = (a - 1 + sps.poisson.cdf(c, 200))/(sps.poisson.cdf(c, 200) - sps.poisson.cdf(c - 1, 200))

print("Полученная константа", c)
print("Полученная вероятность", round(p, 3))

"""Получен наиболее мощный критерий\
$\varphi \left( \vec{X} \right) = \begin{cases} 0, \quad \bar{X} <  4.6 \\ 0.927, \quad \bar{X} =  4.6* \\ 1, \quad \bar{X} >  4.6 \end{cases}$\
\
Т.к. $ \bar{X} = 3.96 < 4.6 \implies H_0$ принимаем.

#### **Пункт H.** В пунктах C-F заменить семейство распределений Пуассона на семейство геометрических распределений: $ \mathbb{P_\lambda} \left( X = k \right) = \frac{\large \lambda^k}{(\lambda + 1)^{k + 1}}, k \in \mathbb{Z_+}$

**c)** $ supp\xi = \mathbb{Z}$\
$E_\theta \xi = \displaystyle \sum^{\infty}_{k=0} k  \frac{\large \lambda^k}{(\lambda + 1)^{k + 1}} = \lambda $\
$ D_\theta \xi = E_\theta(\xi^2) - ( E_\theta(\xi) )^2 = \displaystyle \sum^{\infty}_{k=0} k^2  \frac{\large \lambda^k}{(\lambda + 1)^{k + 1}} - \lambda^2 = \lambda (\lambda + 1)$ \
\
\
Расчёт ОМП \
$ L(\vec{X}, \theta) = \small \displaystyle \prod_{i = 1}^{n} \frac{\large \lambda^{X_i}}{(\lambda + 1)^{X_i + 1}}  = \frac{\large \lambda^{n \bar{X}}}{(\lambda + 1)^{n \bar{X} + n}}$ \
$ LL(\vec{X}, \theta) = n \bar{X} \ ln \lambda - \left( n \bar{X} + n \right) ln (\lambda + 1) $ \
$ \frac{\large \partial LL(\vec{X}, \theta)}{\large \partial \lambda} =  \frac{\large n \bar{X}}{\large \lambda} - \frac{\large n \bar{X} + n}{\lambda + 1} = 0 \implies \hat{\lambda} = \bar{X} = 3.96$ \
\
\
Расчёт ОММ \
$ EX_1 = \lambda $\
$ M_1 = \bar{X} $ \
$ \hat{\lambda} = \bar{X} = 3.96$\
\
\
Оценки совпадают. Посчитаем смещещение оценок.\
$ E \hat{\lambda} = E \bar{X} = \frac{1}{n} E \displaystyle \sum_{i=1}^{n}{X_i} = \frac{1}{n} \displaystyle \sum_{i=1}^{n} E {X_i} = \frac{1}{n} \displaystyle \sum_{i=1}^{n} \lambda  = \frac{\lambda n}{n} = \lambda $\
 Тогда полученные оценки являются несмещёнными.\
 \
 **d)**
 **1 способ.** На основе ОМП. \
$ \displaystyle I_n(\lambda) = -E \frac{\partial^2 LL(\vec{X}, \theta)}{ \partial \lambda^2}$ \
$ \displaystyle \frac{ \partial^2 LL(\vec{X}, \theta)}{\partial \lambda^2} = - \frac{ n \bar{X}}{ \lambda^2} + \frac{ n \bar{X} + n}{(\lambda + 1)^2}$ \
Тогда $ \displaystyle -E \frac{\partial^2 LL(\vec{X}, \theta)}{ \partial \lambda^2} = E\frac{n \bar{X}}{\lambda^2} - E\frac{ n \bar{X} + n}{(\lambda + 1)^2} =  \frac{n}{n\lambda^2}  \sum_{i=1}^{n}EX_i - \frac{1}{(\lambda + 1)^2} \left(\sum_{i=1}^{n}EX_i  + n\right) = \frac{n \lambda}{\lambda^2} - \frac{n(\lambda + 1)}{(\lambda+1)^2} = \frac{n}{\lambda} - \frac{n}{\lambda + 1} = \frac{n}{\lambda (\lambda + 1)}$\
$ \displaystyle I(\lambda) = \frac{1}{\lambda (\lambda + 1)} $

$ \displaystyle x_{a} : Ф(x_a) = 1 - \frac{\large \alpha_1}{\large 2} = 1 - 0.01 = 0.99 \implies x_\alpha = 2.326$\
$ \lambda \in \left[ \bar{X} - \frac{\large x_{\alpha} \sqrt{\bar{X} (\bar{X} + 1)}}{\large \sqrt{n}}; \bar{X} + \frac{\large x_{\alpha} \sqrt{\bar{X} (\bar{X} + 1)}}{\large \sqrt{n}} \right] = [2.502, 5.418]$ \
\
**2 способ.** На основе ЦПТ. \
$ \sqrt{n} \frac{\large \hat{\lambda} - \lambda}{\large \sqrt{\lambda}} \sim \mathcal{N}(0, 1)$ \
$ x_{\alpha} : Ф(x_a) = 1 - \frac{\large \alpha_1}{\large 2} = 1 - 0.01 = 0.99$ \
$ x_{\alpha} = 2.326 $\
$ P_{\lambda} \left( \sqrt{n} \frac{\large \left| \hat{\lambda} - \lambda \right|}{\sqrt{\large \lambda (\lambda + 1)}} \leq x_{\alpha}\right) = 1 - \alpha_1 = 0.98 $ \
\
**2.1)** $ P_{\lambda} \left( \sqrt{n} \frac{\large \left| \bar{X} - \lambda \right|}{\sqrt{\large \lambda (\lambda + 1)}} \leq x_{\alpha}\right) = 0.98 $ \
$ \left| \bar{X} - \lambda \right| \leq \frac{\large x_{\alpha} \sqrt{\lambda (\lambda + 1)}}{\large \sqrt{n}} \implies \left( \bar{X} - \lambda \right) ^ 2 \leq \frac {\large x_{\alpha}^2 \lambda (\lambda + 1)}{\large n} \implies n \left( \bar{X} \right)^2 - 2n \lambda \bar{X} + n \lambda^2 - x_{\alpha}^2 \lambda^2 - x_{\alpha}^2 \lambda \leq 0$\
$\lambda^2 (n - x_\alpha^2) - \lambda \left( 2n \bar{X} + x_{\alpha}^2 \right) + n \left( \bar{X} \right)^2 \leq 0 $ \
$ D = \left( 2n \bar{X} + x_{\alpha}^2 \right) ^ 2 - 4 n \left( \bar{X} \right)^2 (n - x_\alpha^2) = 21282.567 $ \
$ \lambda_1 = \frac{\large 2n \bar{X} + x_{\alpha}^2 - \sqrt{D}}{\large 2(n - x_\alpha^2)} = 3.357 $ \
$ \lambda_2 = \frac{\large 2n \bar{X} + x_{\alpha}^2 + \sqrt{D}}{\large 2(n - x_\alpha^2)} = 4.671 $ \
$ \lambda \in \left[ 2.865, 6.137 \right] $ \
\
**2.2)** $ P_{\lambda} \left( \sqrt{n} \frac{\large \left| \bar{X} - \lambda \right|}{\sqrt{\large \bar{X} (\bar{X} + 1)}} \leq x_{\alpha}\right) = 0.98 $ \
$ -x_{\alpha} \leq \sqrt{n} \frac{\large \bar{X} - \lambda}{\sqrt{\large \bar{X} (\bar{X} + 1)}} \leq x_{\alpha} \implies \bar{X} - \frac{\large x_{\alpha} \sqrt{\bar{X} (\bar{X} + 1)}}{\large \sqrt{n}} \leq \lambda \leq \bar{X} + \frac{\large x_{\alpha} \sqrt{\bar{X} (\bar{X} + 1) }}{\large \sqrt{n}}$ \
$ \lambda \in \left[ 2.502, 5.418 \right] $ \
\
**2.3)** $ P_{\lambda} \left( \sqrt{n} \frac{\large \left| \bar{X} - \lambda \right|}{\large S} \leq x_{\alpha}\right) = 0.98 $ \
$ -x_{\alpha} \leq \sqrt{n} \frac{\large \bar{X} - \lambda}{\large S} \leq x_{\alpha} \implies \bar{X} - \frac{\large x_{\alpha} S}{\large \sqrt{n}} \leq \lambda \leq \bar{X} + \frac{\large x_{\alpha} S}{\large \sqrt{n}}$ \
$ \lambda \in \left[ 3.136, 4.784 \right] $

**e)** Таблица частот \
$ \begin{array}{|c|c|} \hline X_{(i)} & 1 & 2 & 3 & 4 & 5 & 6 & 8 & 9 & 13 \\ \hline \nu(x = X_{(i)})  & 6 & 11 & 9 & 8 & 4 & 6 & 3 & 2 & 1  \\ \hline
\end{array} $

Сгруппируем данные по интевалам.\
$ \begin{array}{|c|c|} \hline j & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9\\ \hline I_j & (-\infty, 1] & (1, 2] & (2, 3] & (3, 4] & (4, 5] & (5, 6] & (6, 8] & (8, 9] & (9, +\infty) \\ \hline \nu_j  & 6 & 11 & 9 & 8 & 4 & 6 & 3 & 2 & 1  \\ \hline
\end{array} $ \
\
$ \measuredangle$ Основную гипотезу $H_0: P_{\lambda}(\xi \in I_j) = P_{\lambda_0}(\xi \in I_j)$ для всех $j = 1...9$ \
и альтернативную - $ H_А: {\exists j}$ $P_{\lambda}(I_j) \neq P_{\lambda_0}(I_j)$ при $j \in 1...9$ \
Гипотеза $ H_0 $ является более слабой по отношению к предложенной в условии, поэтому опровержение $ H_0 $ влечёт за собой опровержение и заданной гипотезы. \
\
Вычислим результаты и структурируем их в таблице \
$ \begin{array}{|c|c|} \hline I_j & \nu_j & p_{j0} & \frac{\large \left( \nu -np_{j0} \right)^2}{\large np_{j0}}\\ \hline (-\infty, 1] & 6 & 0.306 & 5.653 \\ \hline (1, 2] & 11 & 0.116 &  4.662\\ \hline (2, 3] & 9 & 0.096 & 3.675\\ \hline (3, 4] & 8 & 0.08 & 4.0 \\ \hline (4, 5] & 4 & 0.067 & 0.126 \\ \hline (5, 6] & 6 & 0.056 & 3.657 \\ \hline (6, 8] & 3 & 0.085 & 0.368\\ \hline (8, 9] & 2 & 0.032 & 0.1 \\ \hline (9, +\infty) & 1 & 0.162 & 6.223 \\ \hline \end{array} $ \
\
$ \chi^2 = 28.464$\
\
Расчёты получены в результате следующей программы
"""

def Geom(h, x):
  sm = 0

  for i in range(x + 1):
    sm += (h ** i) / (h + 1) ** (i + 1)
  return sm

def CuclSum(h):
  if h == 0:
    return 10**6

  arr = [1, 2, 3, 4, 5, 6, 8, 9]
  res = [0] * (len(arr) + 1)

  #Вычисление p_j0
  res[0] = Geom(h, 1)

  for i in range(1, len(arr)):
    res[i] = Geom(h, arr[i]) - Geom(h, arr[i - 1])
  res[len(arr)] = 1 - Geom(h, 9)
  res = [round(elem, 3) for elem in res]
  print("p_j0 =", res)
  print("Проверка результата. Сумма p_j0 =", sum(res))

  #Вычисление X^2
  v = [6, 11, 9, 8, 4, 6, 3, 2, 1]
  ans = [(v[i] - 50 * res[i]) ** 2 / (50 * res[i]) for i in range(len(v))]
  ans = [round(a, 3) for a in ans]
  print("Последний столбец =", ans)
  print("X^2 =", round(sum(ans), 3))
  return sum(ans)


CuclSum(5)

"""$ x_{a} : \mathcal{K}_{r-1}(x_a) = \mathcal{K}_8(x_a) = 1 - \alpha_1 = 1 - 0.02 = 0.98 \implies x_\alpha = 18.168$\
Т.к. $\chi^2 > x_\alpha$ , то гипотеза отвергается\
Найдём наибольшее значение уровня значимости, на котором нет оснований отвергнуть гипотезу. Пусть $\mathbb{P}(\chi^2 \leq x_\alpha) = 0$\
Тогда $ \chi^2 \leq x_\alpha \implies \chi^2 \leq \mathcal{K}_8^{-1}(1 - \alpha_1) \implies \mathcal{K}_8(\chi^2) \leq 1 - \alpha_1 \implies \alpha_1 \leq 1 - \mathcal{K}_8(\chi^2)$

"""

x_a = 28.464
print("Наибольшее значение уровня значимости =", round(1 - sps.chi2.cdf(x_a, 8), 5))

"""**f)**
Проверим сложную гипотезу $ H_0 : X_1... X_n \sim Pois(\lambda) $ \
Альтернативой ей будет служить $ H_A : X_1 ...X_n$ не распределена, как $Pois(\lambda)$

Таблица интервалов\
$ \begin{array}{|c|c|} \hline j & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9\\ \hline I_j & (-\infty, 1] & (1, 2] & (2, 3] & (3, 4] & (4, 5] & (5, 6] & (6, 8] & (8, 9] & (9, +\infty) \\ \hline \nu_j  & 6 & 11 & 9 & 8 & 4 & 6 & 3 & 2 & 1  \\ \hline
\end{array} $ \

Т.к. гипотеза сложная, то статистикой критерия возьмём $ \tilde{\chi^2} = min_\lambda \chi^2(\lambda) = min_\lambda \displaystyle \sum_{j=1}^{9} \frac{\large \left( \nu_j -np_{j0}(\lambda) \right)^2}{\large np_{j0}(\lambda)} \underset{n \rightarrow \infty}{\implies} \chi^2_{7}$. Размерность $\chi^2$-распределения вычисляется по формуле $ r - d - 1 $, где $r$ - количество интервалов, а $d = dim(\Theta_0)$
"""

def Geom(h, x):
  sm = 0

  for i in range(x + 1):
    sm += (h ** i) / (h + 1) ** (i + 1)
  return sm

def CuclSum(h):
  if h == 0:
    return 10**6

  arr = [1, 2, 3, 4, 5, 6, 8, 9]
  res = [0] * (len(arr) + 1)

  #Вычисление p_j0
  res[0] = Geom(h, 1)
  sm = res[0]

  for i in range(1, len(arr)):
    res[i] = Geom(h, arr[i]) - Geom(h, arr[i - 1])
  res[len(arr)] = 1 - Geom(h, 9)

  #Вычисление X^2
  v = [6, 11, 9, 8, 4, 6, 3, 2, 1]
  ans = [(v[i] - 50 * res[i]) ** 2 / (50 * res[i]) for i in range(len(v))]
  return sum(ans)

result = spo.minimize_scalar(CuclSum)
print("Значение X^2 =", round(result.fun, 3), "при значении параметра =", round(result.x, 3))

"""$ x_{a} : \mathcal{K}_{r-d-1}(x_a) = \mathcal{K}_7(x_a) = 1 - \alpha_1 = 1 - 0.02 = 0.98 \implies x_\alpha = 16.622$\
Т.к. $\chi^2 > x_\alpha$ , то гипотеза отвергается\
\
Найдём наибольшее значение уровня значимости, на котором нет оснований отвергнуть гипотезу. Пусть $\mathbb{P}(\chi^2 \leq x_\alpha) = 0$\
Тогда $ \chi^2 \leq x_\alpha \implies \chi^2 \leq \mathcal{K}_7^{-1}(1 - \alpha_1) \implies \mathcal{K}_7(\chi^2) \leq 1 - \alpha_1 \implies \alpha_1 \leq 1 - \mathcal{K}_7(\chi^2)$

"""

x_a = 26.515
print("Наибольшее значение уровня значимости =", round(1 - sps.chi2.cdf(x_a, 7), 5))

"""### **2 задание**.
#### **Пункт А**. Построить вариационный ряд, эмпирическую функцию распределения, гистограмму и полигон частот с шагом $t = 0.05$.
Первоначальная выборка:
$ \begin{array}{|c|c|} \hline X_{i} & 0.0347 & 0.0253 & -0.0873 & 0.0323 & 0.019 & -0.0266 & 0.1116 & -0.1212 & 0.0725 & 0.0018 & -0.0959 & -0.1773 & -0.1928 & 0.1064 & -0.1606 & -0.2412 & -0.0053 & 0.0637 & 0.1666 & 0.1289 & -0.0745 & -0.0059 & 0.0907 & 0.1211 & 0.0213 & 0.1058 & 0.0129 & -0.1494 & 0.0066 & -0.1275 & 0.0381 & 0.1683 & -0.0047 & -0.0279 & 0.1033 & 0.1309 & -0.1205 & -0.0256 & 0.0276 & 0.0017 & 0.0262 & -0.0784 & -0.0192 & 0.0124 & -0.091 & 0.1777 & 0.0826 & -0.1139 & -0.0166 & -0.0961 \\ \hline
\end{array} $

Вариационный ряд:
$ \begin{array}{|c|c|} \hline X_{i} & -0.2412 & -0.1928 & -0.1773 & -0.1606 & -0.1494 & -0.1275 & -0.1212 & -0.1205 & -0.1139 & -0.0961 & -0.0959 & -0.091 & -0.0873 & -0.0784 & -0.0745 & -0.0279 & -0.0266 & -0.0256 & -0.0192 & -0.0166 & -0.0059 & -0.0053 & -0.0047 & 0.0017 & 0.0018 & 0.0066 & 0.0124 & 0.0129 & 0.019 & 0.0213 & 0.0253 & 0.0262 & 0.0276 & 0.0323 & 0.0347 & 0.0381 & 0.0637 & 0.0725 & 0.0826 & 0.0907 & 0.1033 & 0.1058 & 0.1064 & 0.1116 & 0.1211 & 0.1289 & 0.1309 & 0.1666 & 0.1683 & 0.1777 \\ \hline
\end{array} $

Построим эмпирическую функию распределения $F_n(x) = \frac{1}{n} \displaystyle\sum_{i=1}^{n} \chi \{ X_i < x \}$ и гистограмму частот $ H(x) = \frac{\nu(x)}{nh} $ при $h = 1$.

"""

def VarRow(x):
  arr = [-0.2412, -0.1928, -0.1773, -0.1606, -0.1494, -0.1275, -0.1212, -0.1205, -0.1139, -0.0961, -0.0959, -0.091, -0.0873, -0.0784, -0.0745, -0.0279, -0.0266, -0.0256, -0.0192, -0.0166, -0.0059, -0.0053, -0.0047, 0.0017, 0.0018, 0.0066, 0.0124, 0.0129, 0.019, 0.0213, 0.0253, 0.0262, 0.0276, 0.0323, 0.0347, 0.0381, 0.0637, 0.0725, 0.0826, 0.0907, 0.1033, 0.1058, 0.1064, 0.1116, 0.1211, 0.1289, 0.1309, 0.1666, 0.1683, 0.1777]
  sm = 0
  for pair in arr:
    if pair >= x:
      return sm
    sm += 1
  return sm

x = np.arange(-0.5, 0.5, 0.00001)
y = [VarRow(elem) / 50 for elem in x]




plt.title('График эмпирической функции распределения')
plt.xlabel('x', fontsize=12)
plt.ylabel('Fn(x)', fontsize=12)
plt.plot(x, y, 'red')
plt.show()

arr = [-0.2412, -0.1928, -0.1773, -0.1606, -0.1494, -0.1275, -0.1212, -0.1205, -0.1139, -0.0961, -0.0959, -0.091, -0.0873, -0.0784, -0.0745, -0.0279, -0.0266, -0.0256, -0.0192, -0.0166, -0.0059, -0.0053, -0.0047, 0.0017, 0.0018, 0.0066, 0.0124, 0.0129, 0.019, 0.0213, 0.0253, 0.0262, 0.0276, 0.0323, 0.0347, 0.0381, 0.0637, 0.0725, 0.0826, 0.0907, 0.1033, 0.1058, 0.1064, 0.1116, 0.1211, 0.1289, 0.1309, 0.1666, 0.1683, 0.1777]

plt.title('Гистограмма частот')
plt.xlabel('x', fontsize=12)
plt.ylabel('H(x)', fontsize=12)
counts, bins = np.histogram(arr, bins=[i / 100 for i in range(-25, 25, 5)])
plt.hist(bins[:-1], edgecolor='black', weights=counts / len(arr), bins=bins, color='orange')
plt.plot(bins[:-1] + 0.025, counts / len(arr), color='red')
plt.show()

"""#### **Пункт B**. Вычислить выборочные аналоги следующих числовых характеристик:
(i) математического ожидания; (ii) дисперсии; (iii) СКО; (iv) медианы; (v) асимметрии; (vi) эксцесса; (vii) вероятности $ \mathbb{P}(X \in [-0.04, 0.02]) $.
"""

arr = np.array([-0.2412, -0.1928, -0.1773, -0.1606, -0.1494, -0.1275, -0.1212, -0.1205, -0.1139, -0.0961, -0.0959, -0.091, -0.0873, -0.0784, -0.0745, -0.0279, -0.0266, -0.0256, -0.0192, -0.0166, -0.0059, -0.0053, -0.0047, 0.0017, 0.0018, 0.0066, 0.0124, 0.0129, 0.019, 0.0213, 0.0253, 0.0262, 0.0276, 0.0323, 0.0347, 0.0381, 0.0637, 0.0725, 0.0826, 0.0907, 0.1033, 0.1058, 0.1064, 0.1116, 0.1211, 0.1289, 0.1309, 0.1666, 0.1683, 0.1777])

X = np.mean(arr)
S2 = np.var(arr)
S = np.std(arr)
z = np.median(arr)
asi = np.sum((arr - X)**3) / (50 * S ** 3)
exc = np.sum((arr - X)**4) / (50 * S ** 4) - 3

print("Выборочное среднее =", round(X, 5))
print("Выборочная дисперсия =", round(S2, 5))
print("СКО =", round(S, 5))
print("Выборочная медиана равна =", round(z, 5))
print("Выборочная ассиметрия равна =", round(asi, 5))
print("Выборочный коэффициент эксцесса =", round(exc, 5))
print("Выборочная вероятность попадения в промежуток [-0.04, 0.02] =", (VarRow(0.02) - VarRow(-0.04)) / 50)

"""#### **Пункт C.** В предположении, что исходные наблюдения являются выборкой из нормального распределения, построить оценку максимального правдоподобия параметров $(a, \sigma^2)$ и соответствующие оценки по методу моментов. Найти смещение оценок.

Нормальное распределение: $\xi \sim \mathcal{N}(a, \sigma^2) \implies p_{(a, \sigma^2)}(x) = \frac{1}{\sqrt{2 \pi \sigma^2}} e^{- \frac{\Large (x - a)^2}{\Large 2  \sigma^2}}$ \
$ supp \xi = \mathbb{R}; $ $ E_\theta \xi = a; \ D_\theta \xi = \sigma^2 $ \
\
\
Расчёт ОМП \
$ L(\vec{X}, \theta) = \small \displaystyle \prod_{i = 1}^{n} \frac{1}{\sqrt{2 \pi \sigma^2}} e^{- \frac{\Large (X_i - a)^2}{\Large 2  \sigma^2}} = (2 \pi)^{-\frac{\Large n}{\Large 2}} (\sigma)^{\large -n} e^{- \displaystyle \sum_{i = 1}^{n} \frac{(X_i - a)^2}{2 \sigma^2} }$ \
$ LL(\vec{X}, \theta) = - \frac{n}{2} ln(2 \pi) - n ln \sigma - \displaystyle \sum_{i = 1}^{n} \frac{(X_i - a)^2}{2 \sigma^2}$ \
$ \frac{\large \partial LL(\vec{X}, \theta)}{\large \partial a} = - \displaystyle \sum_{i = 1}^{n} \frac{2(X_i - a)}{2 \sigma^2} (-1) = \displaystyle \sum_{i = 1}^{n} (X_i - a) = \displaystyle \sum_{i = 1}^{n} X_i - na = 0 $ \
$ \hat{a} = \bar{X} = -0.00339 $\
\
$ \frac{\large \partial LL(\vec{X}, \theta)}{\large \partial \sigma} = - \frac{\Large n}{\Large \sigma} + \displaystyle \sum_{i = 1}^{n} \frac{(X_i - a)^2}{ \sigma^3} = 0 $\
$ - \sigma^2 n + \displaystyle \sum_{i = 1}^{n} (X_i - a)^2 = 0 $\
$ \widehat{\sigma^2} = \frac{\displaystyle \sum_{i = 1}^{n} (X_i - a)^2}{\Large n} = \frac{\displaystyle \sum_{i = 1}^{n} (X_i - \bar{X})^2}{\Large n} = S^2 = 0.00989$
\
\
Расчёт ОММ \
$ EX_1 = a; \quad M_1 = \bar{X} $ \
$ EX_1^2 = DX_1 + (EX_1)^2 = \sigma^2 + a^2 ; \quad M_1 = \displaystyle \frac{1}{n}  \sum_{i = 1}^{n} X_i^2 = \bar{X^2} $ \
$\begin{cases} \tilde{a} = \bar{X} \\ a^2 + \sigma^2 = \bar{X^2} \end{cases} \quad \begin{cases} \tilde{a} = \bar{X} \\ (\bar{X})^2 + \sigma^2 = \bar{X^2} \end{cases} \quad \begin{cases} \tilde{a} = \bar{X} = -0.00339 \\ \tilde{\sigma^2} = S^2 = 0.00989 \end{cases} $
\
\
Оценки совпадают. Посчитаем смещещение оценок.\
$ E \hat{a} = E \bar{X} = \frac{1}{n} E \displaystyle \sum_{i=1}^{n}{X_i} = \frac{1}{n} \displaystyle \sum_{i=1}^{n} E {X_i} = \frac{1}{n} \displaystyle \sum_{i=1}^{n} a  = \frac{a n}{n} = a $\
Несмещённая оценка \
\
$ E \hat{\sigma^2} = E S^2 = E \displaystyle \sum_{i = 1}^{n} (X_i - \bar{X})^2 = [ X_i - E_\theta X_i = Y_i ] = $ \
 $[ E_\theta Y_i = 0 \quad D_\theta Y_i = \sigma^2 ]$ \
  $= \frac{1}{n} E_\theta \sum_{i = 1}^{n} (Y_i - \bar{Y}) = \frac{1}{n} E_\theta (\bar{Y} - (\bar{Y})^2) = E \bar{Y^2} - E(\bar{Y})^2 $\
$ \displaystyle E(\bar{Y^2}) = \frac{1}{n} E \sum_{i=1}^{n} Y_i^2  = \frac{1}{n} \sum_{i=1}^{n} EY_i^2 = \sigma^2 $\
$ \displaystyle E(\bar{Y})^2 = \frac{1}{n^2} E( \sum_{i=1}^{n} Y_i )^2 = \frac{1}{n} \sum_{i=1}^{n} \sum_{j=1}^{n}EY_i Y_j$\
$ EY_i Y_j = \begin{cases} \sigma^2 \quad i=j \\ 0 \quad i \neq j \end{cases} $\
$ \displaystyle E_\theta S^2 = \sigma^2 - \frac{\sigma^2}{n} = \frac{n - 1}{n} \sigma^2$\
Смещённая оценка\
$ (S')^2 = \frac{n}{n - 1} S^2 $

#### **Пункт D.** Построить доверительные интервалы уровня значимости $a_2 = 0.05$ для параметров $ (a, \sigma^2) $

Доверительный интервал для параметра $a$.\
По лемме Фишера выберем генератор $ G(\vec{X}, a) = \sqrt{n - 1} \frac{\bar{X} - a}{S} \sim S_{n - 1} $\
$ \mathbb{P}_a \left( \sqrt{n - 1} \frac{\bar{X} - a}{S} \in [-x_\alpha; x_\alpha] \right) = 1 - \alpha_2 $\
$ x_\alpha : S_{n - 1}(x_\alpha) = S_{49}(x_\alpha) = 1 - \frac{\alpha_2}{2} = 0.975  $
"""

fx = 0.975
x_a = sps.t.ppf(fx, 49)

print("Квантиль x_a =", round(x_a, 3))
print("Функция распределения S_49(x_a) =", round(sps.t.cdf(x_a, 49), 3))

"""$ \displaystyle a \in \left[  \bar{X} - \frac{x_\alpha S}{\sqrt{n-  1}}; \bar{X} + \frac{x_\alpha S}{\sqrt{n-  1}} \right] = [-0.03195; 0.02517]$


---

Доверительный интеврал для параметра $\sigma^2$
По лемме Фишера выберем генератор $ \displaystyle G(\vec{X}, \sigma^2) = \frac{nS^2}{\sigma^2} \sim \chi^2_{n - 1}$\
$ \mathbb{P}_{\sigma^2} \left( \frac{nS^2}{\sigma^2} \in [-x_\alpha; x_\alpha] \right) = 1 - \alpha_2 $\
$ x_{1\alpha} : \mathcal{K}_{n - 1}(x_{1\alpha}) = \mathcal{K}_{49}(x_{1\alpha}) = \frac{\alpha_2}{2} = 0.025  $\
$ x_{2\alpha} : \mathcal{K}_{n - 1}(x_{2\alpha}) = \mathcal{K}_{49}(x_{2\alpha}) = 1 - \frac{\alpha_2}{2} = 0.975 $


"""

x_1a = sps.chi2.ppf(0.025, 49)
x_2a = sps.chi2.ppf(0.975, 49)

print("Квантиль x_1a =", round(x_1a, 3), "Квантиль x_2a =", round(x_2a, 3))
print("Функция распределения K_8(x_1a) =", round(sps.chi2.cdf(x_1a, 49), 3), "K_8(x_2a) =", round(sps.chi2.cdf(x_2a, 49), 3))

"""$ \displaystyle \sigma^2 \in \left[  \frac{n S^2}{x_{2\alpha}}; \frac{n S^2}{x_{1\alpha}} \right] = [0.00704; 0.01567]$

#### **Пункт E** С использованием теоремы Колмогорова построить критерий значимости проверки простой гипотезы согласия с нормальным распределением с параметрами $ (\alpha_0 = -0.11, \sigma_0^2 = 0.01) $. Проверить гипотезу на уровне значимости $ a_2 = 0.05 $. Вычислить наибольшее значение уровня значимости, на котором ещё нет оснований отвергнуть данную гипотезу.

Основаня гипотеза $ H_0 : X_1...X_n \sim \mathcal{N}(\alpha_0, \sigma_0^2) $\
Альтернативная гипотеза $ H_А : X_1...X_n$ не распределена, как $\mathcal{N}(\alpha_0, \sigma_0^2) $

Статистика критерия Колмогорова $ \widehat{D_n} = max| F_n(x) - Ф_{(\alpha_0, \sigma_0^2)}(x) | $. Построим критерий Колмогорова.\
$\widehat{\varphi(\vec{X})} = \begin{cases} 0, \quad \widehat{D_n} \leq x_\alpha  \\ 1, \quad \widehat{D_n} > x_\alpha \end{cases}$, где $ x_\alpha: \mathcal{K_n}(x_\alpha) = 1 - \alpha_2 = 0.95 $\
\
Найдём $ x_a $
"""

fx = 0.95
x_a = sps.ksone.ppf(fx, 50)


print("При квантиле x_a =", round(x_a, 3))
print("K_50(x) =", round(sps.ksone.cdf(x_a, 50), 3))

"""Критерий Колмогорова\
$\widehat{\varphi(\vec{X})} = \begin{cases} 0, \quad \widehat{D_n} \leq 0.17  \\ 1, \quad \widehat{D_n} > 0.17 \end{cases}$

Найдём $D_n$
"""

def Fn(x):
  arr = [-0.2412, -0.1928, -0.1773, -0.1606, -0.1494, -0.1275, -0.1212, -0.1205, -0.1139, -0.0961, -0.0959, -0.091, -0.0873, -0.0784, -0.0745, -0.0279, -0.0266, -0.0256, -0.0192, -0.0166, -0.0059, -0.0053, -0.0047, 0.0017, 0.0018, 0.0066, 0.0124, 0.0129, 0.019, 0.0213, 0.0253, 0.0262, 0.0276, 0.0323, 0.0347, 0.0381, 0.0637, 0.0725, 0.0826, 0.0907, 0.1033, 0.1058, 0.1064, 0.1116, 0.1211, 0.1289, 0.1309, 0.1666, 0.1683, 0.1777]
  sm = 0
  for pair in arr:
    if pair >= x:
      return sm / 50
    sm += 1
  return sm / 50

x = np.arange(-1, 1, 0.001)
y = [abs(Fn(elem) - sps.norm.cdf(elem, -0.11, 0.1)) for elem in x]


print("Статистика Dn =", round(max(y), 3))

"""Т.к. $\widehat{D_n} > x_\alpha$, гипотеза $H_0$ отвергается.\
Вычислим наибольшее значение уровня значимости, на котором нет оснований отвергнуть гипотезу. Пусть $ P(\widehat{D_n} \leq x_\alpha) = 0$.\
$ \widehat{D_n} \leq x_\alpha \implies \widehat{D_n} \leq \mathcal{K_{50}^{-1}}(1 - \alpha_2) \implies \mathcal{K_{50}}(\widehat{D_n}) \leq 1 - \alpha_2 \implies \alpha_2 \leq 1 - \mathcal{K_{50}}(\widehat{D_n})$
"""

x_a = 0.494
print("Наибольший уровень значимости a_2 =", 1 - sps.ksone.cdf(x_a, 50))

"""#### **Пункт F** Используя гистограмму частот, построить критерий значимости $\chi^2$ проверки простой гипотезы согласия с нормальным распределением с параметрами $ ( \alpha_0 = -0.11, \sigma^2 = 0.01 ) $. Проверить гипотезу на уровне значимости $\alpha_2 = 0.05$. Вычислить наибольшее значение уровня значимости, на котором ещё нет оснований отвергнуть данную гипотезу.

Таблица частот \
$ \begin{array}{|c|c|} \hline X_{(i)} & -0.2 & -0.15 & -0.1 & -0.05 & 0 & 0.05 & 0.1 & 0.15 & 0.2 \\ \hline \nu(x = X_{(i)})  & 1 & 3 & 5 & 6 & 8 & 13 & 4 & 7 & 3  \\ \hline
\end{array} $

Сгруппируем данные по интевалам.\
$ \begin{array}{|c|c|} \hline j & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9\\ \hline I_j & (-\infty, -0.2] & (-0.2, -0.15] & (-0.15, -0.1] & (-0.1, -0.05] & (-0.05, 0] & (0, 0.05] & (0.05, 0.1] & (0.1, 0.15] & (0.15, +\infty) \\ \hline \nu_j  & 1 & 3 & 5 & 6 & 8 & 13 & 4 & 7 & 3  \\ \hline
\end{array} $ \
\
$ \measuredangle$ Основную гипотезу $H_0: Ф(I_j) = Ф_{(\alpha_0, \sigma_0^2)}(I_j)$ для всех $j=1...9$ \
и альтернативную - $ H_А: {\exists j} \ Ф(I_j) \neq Ф_{(\alpha_0, \sigma_0^2)}(I_j)$, где $ j=1...9 $\
Гипотеза $ H_0 $ является более слабой по отношению к предложенной в условии, поэтому опровержение $ H_0 $ влечёт за собой опровержение и заданной гипотезы. \
\
Вычислим результаты и структурируем их в таблице \
$ \begin{array}{|c|c|} \hline I_j & \nu_j & p_{j0} & \frac{\large \left( \nu -np_{j0} \right)^2}{\large np_{j0}}\\ \hline (-\infty, -0.2] & 1 & 0.18406 & 7.312 \\ \hline (-0.2, -0.15] & 3 & 0.16052 &  3.147\\ \hline (-0.15, -0.1] & 5 & 0.19525 & 2.323\\ \hline (-0.1, -0.05] & 6 & 0.18592 & 1.169 \\ \hline (-0.05, 0] & 8 & 0.13859 & 0.165 \\ \hline (0, 0.05] & 13 & 0.08087 & 19.839 \\ \hline (0.05, 0.1] & 4 & 0.03693 & 2.512\\ \hline (0.1, 0.15] & 7 & 0.0132 & 60.902 \\ \hline (0.15, +\infty) & 3 & 0.00466 & 32.86 \\ \hline \end{array} $ \
\
$ \chi^2 = 130.229$\
\
Расчёты получены в результате следующей программы

"""

def CuclSum(a, g2):
  arr = [-0.2, -0.15, -0.1, -0.05, 0, 0.05, 0.1, 0.15]
  res = [0] * (len(arr) + 1)

  #Вычисление p_j0
  res[0] = sps.norm.cdf(-0.2, a, g2)

  for i in range(1, len(arr)):
    res[i] = sps.norm.cdf(arr[i], a, g2) - sps.norm.cdf(arr[i - 1], a, g2)
  res[len(arr)] = 1 - sps.norm.cdf(0.15, a, g2)
  res = [round(elem, 5) for elem in res]
  print("p_j0 =", res)
  print("Проверка результата. Сумма p_j0 =", sum(res))

  #Вычисление X^2
  v = [1, 3, 5, 6, 8, 13, 4, 7, 3]
  ans = [(v[i] - 50 * res[i]) ** 2 / (50 * res[i]) for i in range(len(v))]
  ans = [round(elem, 3) for elem in ans]
  print("Последний столбец =", ans)

  return sum(ans)

print("X^2 =", round(CuclSum(-0.11, 0.1), 3))

"""$ x_{a} : \mathcal{K}_{r-1}(x_a) = \mathcal{K}_8(x_a) = 1 - \alpha_2 = 1 - 0.02 = 0.98$"""

fx = 0.95
x_a = sps.chi2.ppf(fx, 8)

print("Квантиль x_a =", round(x_a, 3))
print("Функция распределения K_8(x_a) =", sps.chi2.cdf(x_a, 8))

"""Т.к. $\chi^2 > x_\alpha$ , то гипотеза отвергается\
Найдём наибольшее значение уровня значимости, на котором нет оснований отвергнуть гипотезу. Пусть $\mathbb{P}(\chi^2 \leq x_\alpha) = 0$\
Тогда $ \chi^2 \leq x_\alpha \implies \chi^2 \leq \mathcal{K}_8^{-1}(1 - \alpha_1) \implies \mathcal{K}_8(\chi^2) \leq 1 - \alpha_1 \implies \alpha_1 \leq 1 - \mathcal{K}_8(\chi^2)$

"""

x_a = 130.229
print("Наибольшее значение уровня значимости =", 1 - sps.chi2.cdf(x_a, 8))

"""#### **Пункт G.** Построить критерий проверки значимости $\chi^2$ сложной гипотезы согласия с нормальным распределением. Проверить гипотезу на уровне значимости $\alpha_2$. Вычислить наибольшее значение уровня значимости, на котором ещё нет оснований отвергнуть данную гипотезу.

Проверим сложную гипотезу $ H_0 : X_1... X_n \sim \mathcal{N}(a, \sigma^2) $ \
Альтернативой ей будет служить $ H_A : X_1 ...X_n$ не распределена, как $\mathcal{N}(a, \sigma^2)$

Таблица частот \
$ \begin{array}{|c|c|} \hline X_{(i)} & -0.2 & -0.15 & -0.1 & -0.05 & 0 & 0.05 & 0.1 & 0.15 & 0.2 \\ \hline \nu(x = X_{(i)})  & 1 & 3 & 5 & 6 & 8 & 13 & 4 & 7 & 3  \\ \hline
\end{array} $

Сгруппируем данные по интевалам (в каждом интервале не менее 5 элементов).\
$ \begin{array}{|c|c|} \hline j & 1 & 2 & 3 & 4 & 5\\ \hline I_j & (-\infty, -0.1] &  (-0.1, -0.05] & (-0.05, 0] & (0, 0.05] & (0.05, +\infty) \\ \hline \nu_j  & 9 & 6 & 8 & 13 & 14  \\ \hline
\end{array} $ \

Т.к. гипотеза сложная, то статистикой критерия возьмём $ \tilde{\chi^2} = min_\lambda \chi^2(\lambda) = min_\lambda \displaystyle \sum_{j=1}^{5} \frac{\large \left( \nu_j -np_{j0}(\lambda) \right)^2}{\large np_{j0}(\lambda)} \underset{n \rightarrow \infty}{\implies} \chi^2_{2}$. Размерность $\chi^2$-распределения вычисляется по формуле $ r - d - 1 $, где $r$ - количество интервалов, а $d = dim(\Theta_0)$
"""

def CuclSum(args):
  arr = [-0.2, -0.15, -0.1, -0.05, 0, 0.05, 0.1, 0.15]
  res = [0] * (len(arr) + 1)

  #Вычисление p_j0
  res[0] = sps.norm.cdf(-0.2, args[0], args[1])

  for i in range(1, len(arr)):
    res[i] = sps.norm.cdf(arr[i],args[0], args[1]) - sps.norm.cdf(arr[i - 1], args[0], args[1])
  res[len(arr)] = 1 - sps.norm.cdf(0.15, args[0], args[1])

  #Вычисление X^2
  v = [1, 3, 5, 6, 8, 13, 4, 7, 3]
  ans = [(v[i] - 50 * res[i]) ** 2 / (50 * res[i]) for i in range(len(v))]

  return sum(ans)

result = spo.minimize(CuclSum, (-0.11, 0.1))

print("Значение X^2 =", round(result.fun, 5), "при значении параметров (", round(result.x[0], 5), round(result.x[1], 5), ")")

"""$ x_{a} : \mathcal{K}_{r-d-1}(x_a) = \mathcal{K}_2(x_a) = 1 - \alpha_2 = 1 - 0.05 = 0.95$"""

fx = 0.95
x_a = sps.chi2.ppf(fx, 2)

print("Квантиль x_a =", round(x_a, 3))
print("Функция распределения K_8(x_a) =", sps.chi2.cdf(x_a, 2))

"""Т.к. $\chi^2 < x_\alpha$ , то гипотеза принимается\
Найдём наибольшее значение уровня значимости, на котором нет оснований отвергнуть гипотезу. Пусть $\mathbb{P}(\chi^2 \leq x_\alpha) = 0$\
Тогда $ \chi^2 \leq x_\alpha \implies \chi^2 \leq \mathcal{K}_2^{-1}(1 - \alpha_1) \implies \mathcal{K}_2(\chi^2) \leq 1 - \alpha_1 \implies \alpha_1 \leq 1 - \mathcal{K}_2(\chi^2)$

"""

x_a = 4.9747
print("Наибольшее значение уровня значимости =", round(1 - sps.chi2.cdf(x_a, 2), 3))

"""#### **Пункт H** Построить наиболее мощный критерий проверки простой гипотезы о нормальности с параметром $ (a, \sigma^2) = (a_0 = -0.11,\ \sigma^2_0 = 0.1^2) $ при альтернативе нормальности с параметром $ (a, \sigma^2) = (a_1 = 0,\ \sigma^2_1 = 0.1^2) $. Проверить гипотезу на уровне значимости $\alpha_2$. Что получится, если поменять местами основную и альтернативную гипотезы?

Рассмотрим две гипотезы. \
Проверим сложную гипотезу $ H_0 : X_1... X_n \sim \mathcal{N}(a_0, \sigma^2_0)$\
Альтернативную гипотезу $ H_А : X_1... X_n \sim \mathcal{N}(a_1, \sigma^2_1)$\
\
По лемме Неймана-Пирса\
$\varphi \left( \vec{X} \right) = \begin{cases} 0, \quad LR \left( \vec{X}, (a_1, \sigma^2_1), (a_0, \sigma^2_0) \right) < x_\alpha \\ p, \quad LR \left( \vec{X}, (a_1, \sigma^2_1), (a_0, \sigma^2_0) \right) = x_\alpha \\ 1, \quad LR \left( \vec{X}, (a_1, \sigma^2_1),(a_0, \sigma^2_0) \right) > x_\alpha \end{cases}$, где $LR \left( \vec{X}, (a_1, \sigma^2_1), (a_0, \sigma^2_0) \right) = \frac{\large L \left( \vec{X}, (a_1, \sigma^2_1) \right)}{\large L \left( \vec{X}, (a_0, \sigma^2_0) \right)}$

Из пункта C\
$ L(\vec{X}, (a_1, \sigma^2_1)) = (2 \pi)^{-\frac{\Large n}{\Large 2}} (\sigma_1)^{\large -n} e^{- \displaystyle \sum_{i = 1}^{n} \frac{(X_i - a_1)^2}{2 \sigma^2_1} }= (2 \pi)^{-\frac{\Large n}{\Large 2}} (\sigma_1)^{\large -n} e^{- \displaystyle \sum_{i = 1}^{n} \frac{(X^2_i - 2a_1X_i + a_1^2)}{2 \sigma_1^2} }$\
$ L(\vec{X}, (a_0, \sigma^2_0)) = (2 \pi)^{-\frac{\Large n}{\Large 2}} (\sigma_0)^{\large -n} e^{- \displaystyle \sum_{i = 1}^{n} \frac{(X_i - a_0)^2}{2 \sigma^2_0} }= (2 \pi)^{-\frac{\Large n}{\Large 2}} (\sigma_0)^{\large -n} e^{- \displaystyle \sum_{i = 1}^{n} \frac{(X^2_i - 2a_0X_i + a_0^2)}{2 \sigma_0^2} }$\
Тогда $\frac{\large L \left( \vec{X}, (a_1, \sigma^2_1) \right)}{\large L \left( \vec{X}, (a_0, \sigma^2_0) \right)} = \displaystyle \left( \frac{\sigma_0}{\sigma_1} \right)^n exp \left( \sum_{i=1}^{n}\frac{X_i^2 - 2a_0X_i + a_0^2}{2 \sigma^2_0} - \sum_{i=1}^{n}\frac{X_i^2 - 2a_1X_i + a_1^2}{2 \sigma^2_1} \right) = $\
Заметим, что $ \sigma_1 = \sigma_0 = \sigma $\
$ = \displaystyle exp \left(  \frac{a_1 - a_0}{\sigma^2} \sum_{i=1}^{n} X_i + \frac{n(a_0^2 - a_1^2)}{2 \sigma^2}  \right) = exp \left( 11 \sum_{i=1}^{n} X_i + 30.25 \right)$\
$T = \displaystyle \sum_{i = 1}^{n} X_i$ - МДС\
\
Пусть $ LR \left( \vec{X}, \lambda_1, \lambda_0 \right) > x_\alpha $ \
$ \displaystyle exp \left( 11 \sum_{i=1}^{n} X_i + 30.25 \right) > x_\alpha $\
\
$  \displaystyle \left( 11 \sum_{i=1}^{n} X_i + 30.25 \right) > lnx_\alpha $\
\
$ \displaystyle \sum_{i=1}^{n} X_i  \  > x_a^* = \left(\frac{ln x_\alpha - 30.25}{11} \right) $\
\
$ \displaystyle \varphi \left( \vec{X} \right) = \begin{cases} 0, \quad \sum_{i=1}^{n} X_i <  x_\alpha^* \\ p, \quad \sum_{i=1}^{n} X_i =  x_\alpha^* \\ 1, \quad \sum_{i=1}^{n} X_i >  x_\alpha^* \end{cases}$
\
\
Вычислим $ x_\alpha^*$ и $ p $, учитывая, что выборка из нормального распределения. \
$ \displaystyle E_{(a_0, \sigma^2_0)} \varphi(\vec{X}) = \mathbb{P_{(a_0, \sigma^2_0)}} \left( \sum_{i=1}^{n} X_i > x_a^* \right) + p \ \mathbb{P_{(a_0, \sigma^2_0)}} \left( \sum_{i=1}^{n} X_i = x_a^* \right) = \alpha_2$\
$ \displaystyle \mathbb{P_{(a_0, \sigma^2_0)}} \left( \sum_{i=1}^{n} X_i > x_a^* \right) = 1 - \mathbb{P_{(a_0, \sigma^2_0)}} \left( \sum_{i=1}^{n} X_i \leq x_a^* \right) = 1 - Ф_{(na_0, n\sigma^2_0)}(x_\alpha)$\
\
Подбираем $x_\alpha$\
$ 1 - Ф_{(na_0, n\sigma^2_0)}(x_\alpha) < \alpha_2 $. Тогда $\alpha_2 = 2.7243.$ \
\
Считаем p\
$ p = \frac{\large \alpha_2 - 1 + Ф_{(na_0, n\sigma^2_0)}(x_\alpha)}{ Ф_{(na_0, n\sigma^2_0)}(x_\alpha) - Ф_{(na_0, n\sigma^2_0)}(x_\alpha - 1)} = 0$\
\
Расчёты были воспроизведены в программе ниже


"""

a = 0.05
c = -100
while True:
  if 1 - sps.norm.cdf(c, 50 * -0.11, 50 * 0.1) < a:
    break
  c += 0.001

p = (a - 1 + sps.norm.cdf(c, -0.11 * 50, 50 * 0.1))/(sps.norm.cdf(c, -0.11 * 50, 0.1 * 50) - sps.norm.cdf(c - 1, -0.11 * 50, 0.1 * 50))

print("Полученная константа", round(c, 5))
print("Полученная вероятность", round(p, 3))

"""Получен наиболее мощный критерий\
$\varphi \left( \vec{X} \right) = \begin{cases} 0, \quad \sum_{i=1}^{n} X_i \leq  2.7243 \\  1, \quad \sum_{i=1}^{n} X_i >  2.7243 \end{cases}$\
\
Т.к. $ \sum_{i=1}^{n} X_i = −0,1695 < 2.7243 \implies H_0$ принимаем.

Поменяем гипотезы местами. \
Проверим сложную гипотезу $ H_0 : X_1... X_n \sim \mathcal{N}(a_1, \sigma^2_1)$\
Альтернативную гипотезу $ H_А : X_1... X_n \sim \mathcal{N}(a_0, \sigma^2_0)$\
\
По лемме Неймана-Пирса\
$\varphi \left( \vec{X} \right) = \begin{cases} 0, \quad LR \left( \vec{X}, (a_0, \sigma^2_0), (a_1, \sigma^2_1) \right) < x_\alpha \\ p, \quad LR \left( \vec{X}, a_0, \sigma^2_0), (a_1, \sigma^2_1) \right) = x_\alpha \\ 1, \quad LR \left( \vec{X}, a_0, \sigma^2_0), (a_1, \sigma^2_1) \right) > x_\alpha \end{cases}$, где $LR \left( \vec{X}, (a_0, \sigma^2_0), (a_1, \sigma^2_1) \right) = \frac{\large L \left( \vec{X}, (a_0, \sigma^2_0) \right)}{\large L \left( \vec{X}, (a_1, \sigma^2_1) \right)}$

Из пункта C\
$ L(\vec{X}, (a_1, \sigma^2_1)) = (2 \pi)^{-\frac{\Large n}{\Large 2}} (\sigma_1)^{\large -n} e^{- \displaystyle \sum_{i = 1}^{n} \frac{(X_i - a_1)^2}{2 \sigma^2_1} }= (2 \pi)^{-\frac{\Large n}{\Large 2}} (\sigma_1)^{\large -n} e^{- \displaystyle \sum_{i = 1}^{n} \frac{(X^2_i - 2a_1X_i + a_1^2)}{2 \sigma_1^2} }$\
$ L(\vec{X}, (a_0, \sigma^2_0)) = (2 \pi)^{-\frac{\Large n}{\Large 2}} (\sigma_0)^{\large -n} e^{- \displaystyle \sum_{i = 1}^{n} \frac{(X_i - a_0)^2}{2 \sigma^2_0} }= (2 \pi)^{-\frac{\Large n}{\Large 2}} (\sigma_0)^{\large -n} e^{- \displaystyle \sum_{i = 1}^{n} \frac{(X^2_i - 2a_0X_i + a_0^2)}{2 \sigma_0^2} }$\
Тогда $\frac{\large L \left( \vec{X}, (a_0, \sigma^2_0) \right)}{\large L \left( \vec{X}, (a_1, \sigma^2_1) \right)} = \displaystyle \left( \frac{\sigma_1}{\sigma_0} \right)^n exp \left( \sum_{i=1}^{n}\frac{X_i^2 - 2a_1X_i + a_1^2}{2 \sigma^2_1} - \sum_{i=1}^{n}\frac{X_i^2 - 2a_0X_i + a_0^2}{2 \sigma^2_0} \right) = $\
Заметим, что $ \sigma_1 = \sigma_0 = \sigma $\
$ = \displaystyle exp \left(  \frac{a_0 - a_1}{\sigma^2} \sum_{i=1}^{n} X_i + \frac{n(a_1^2 - a_0^2)}{2 \sigma^2}  \right) = exp \left( -11 \sum_{i=1}^{n} X_i - 30.25 \right)$\
$T = \displaystyle \sum_{i = 1}^{n} X_i$ - МДС\
\
Пусть $ LR \left( \vec{X}, \lambda_1, \lambda_0 \right) > x_\alpha $ \
$ \displaystyle exp \left( -11 \sum_{i=1}^{n} X_i - 30.25 \right) > x_\alpha $\
\
$  \displaystyle \left( -11 \sum_{i=1}^{n} X_i - 30.25 \right) > lnx_\alpha $\
\
$ \displaystyle \sum_{i=1}^{n} X_i  \  < x_a^* = -\left(\frac{ln x_\alpha + 30.25}{11} \right) $\
\
$ \displaystyle \varphi \left( \vec{X} \right) = \begin{cases} 0, \quad \sum_{i=1}^{n} X_i >  x_\alpha^* \\ p, \quad \sum_{i=1}^{n} X_i =  x_\alpha^* \\ 1, \quad \sum_{i=1}^{n} X_i <  x_\alpha^* \end{cases}$
\
\
Вычислим $ x_\alpha^*$ и $ p $, учитывая, что выборка из нормального распределения. \
$ \displaystyle E_{(a_1, \sigma^2_1)} \varphi(\vec{X}) = \mathbb{P_{(a_1, \sigma^2_1)}} \left( \sum_{i=1}^{n} X_i < x_a^* \right) + p \ \mathbb{P_{(a_1, \sigma^2_1)}} \left( \sum_{i=1}^{n} X_i = x_a^* \right) = \alpha_2$\
$ \displaystyle \mathbb{P_{(a_1, \sigma^2_1)}} \left( \sum_{i=1}^{n} X_i \leq x_a^* \right) = Ф_{(na_1, n\sigma^2_1)}(x_\alpha)$\
\
Подбираем $x_\alpha$\
$ Ф_{(na_1, n\sigma^2_1)}(x_\alpha) > \alpha_2 $. Тогда $\alpha_2 = -8.224.$ \
\
Считаем p\
$ p = \frac{\large \alpha_2 - Ф_{(na_0, n\sigma^2_0)}(x_\alpha)}{ Ф_{(na_0, n\sigma^2_0)}(x_\alpha) - Ф_{(na_0, n\sigma^2_0)}(x_\alpha - 1)} = 0$\
\
Расчёты были воспроизведены в программе ниже
"""

a = 0.05
c = -100

while True:
  if sps.norm.cdf(c, 0, 50 * 0.1) > a:
    break
  c += 0.001

p = (a - sps.norm.cdf(c, 0, 50 * 0.1))/(sps.norm.cdf(c, 0, 0.1 * 50) - sps.norm.cdf(c - 1, 0, 0.1 * 50))

print("Полученная константа", round(c, 5))
print("Полученная вероятность", round(p, 3))

"""Получен наиболее мощный критерий\
$\varphi \left( \vec{X} \right) = \begin{cases} 0, \quad \sum_{i=1}^{n} X_i \geq  -8.224 \\  1, \quad \sum_{i=1}^{n} X_i <  -8.224 \end{cases}$\
\
Т.к. $ \sum_{i=1}^{n} X_i = −0,1695 > -8.224 \implies H_0$ отвергается.

#### **Пункт I** В пунктах C-G заменить семейство нормальных распределений на двухпараметрическое семейство распредленией Лапласа с плотностями $ \displaystyle p_{a, \sigma}(x)=\frac{1}{\sigma \sqrt{2}} e^{\left(-\frac{\sqrt{2}}{\sigma} |x-a| \right)} $

**с)** $ E_\theta \xi = a; \ D_\theta \xi = \frac{\sigma a }{\sqrt{2}} $\
\
\
Расчёт ОМП\
$L(\vec{X}, \theta) = \displaystyle \prod_{i=1}^{n} \frac{1}{\sigma \sqrt{2}} e^{(-\frac{\sqrt{2}}{\sigma} |x-a|)} = (2 \sigma^2)^{-\frac{n}{2}} e^{(-\frac{\sqrt{2}}{\sigma} \displaystyle \sum_{i=1}^{n} |x_i-a|)} $

$LL(\vec{X}, \theta) = \displaystyle -\frac{n}{2} ln(2) - nln(\sigma) -\frac{\sqrt{2}}{\sigma} \sum_{i=1}^{n} |x_i-a|$

$ \cfrac{\partial LL(\vec{X}, \theta)}{\partial a} = \displaystyle  -\frac{\sqrt{2}}{\sigma} \sum_{i=1}^{n} sgn(X_{(i)} - a) = 0$

$ \widehat{a} = z_{n, 0.5} = 0.0042$

$ \cfrac{ \partial LL(\vec{X}, \theta)}{ \partial \sigma} = -\frac{n}{\sigma} + \frac{\sqrt{2}}{\sigma^2} \displaystyle \sum_{i=1}^{n} |x_i-a| = 0$

$\widehat \sigma = \sqrt{2} \cfrac{\sum_{i=1}^{n} |x_i- z_{n, 0.5}|}{n} = 0.112$\
\
\
Расчёт ОММ

Первый момент
$ EX_1 = \displaystyle \frac{1}{\sigma \sqrt{2}} \int_{- \infty}^{\infty} x e^{(-\frac{\sqrt{2}}{\sigma} |x-a|)} dx = [t = x - a] = \frac{1}{\sigma \sqrt{2}} \int_{-\infty}^{\infty} (t + a) e^{(-\frac{\sqrt{2}}{\sigma} |t|)} dx = \frac{a}{\sigma} \sqrt{2} \int_{0}^{\infty} e^{(-\frac{\sqrt{2}}{\sigma} t)} dx = a, \quad M1 = \bar X$ \


\
Второй момент
$ EX_1^2 = \displaystyle \frac{1}{\sigma \sqrt{2}} \int_{- \infty}^{\infty} x^2 e^{(-\frac{\sqrt{2}}{\sigma} |x-a|)} dx = [t = x - a] = \frac{1}{\sigma \sqrt{2}} \int_{- \infty}^{\infty} (t + a)^2 e^{(-\frac{\sqrt{2}}{\sigma} |t|)} dx$

Раскладываем $ (t + a)^2 = t^2 + 2at + a^2 $. В силу нечётности слагаемое 2at при разбиение интграла сократится.
$\displaystyle \frac{1}{\sigma \sqrt{2}} \int_{- \infty}^{\infty} t^2 \exp(-\frac{\sqrt{2}}{\sigma} |t|) dx + \frac{1}{\sigma \sqrt{2}} \int_{- \infty}^{\infty} a^2 \exp(-\frac{\sqrt{2}}{\sigma} |t|) dx = \frac{ \sqrt{2}}{\sigma} \int_{0}^{\infty} t^2 \exp(-\frac{\sqrt{2}}{\sigma} t) dx + \frac{\sqrt{2}}{\sigma } \int_{0}^{\infty} a^2 \exp(-\frac{\sqrt{2}}{\sigma} t) dx = \sigma^2 + a^2, \quad M1 = \bar {X^2}$


Составляем систему уравнений\
$
\begin{cases}
  a = \bar X \\
  \sigma^2 + a^2 = \bar X^2
\end{cases} $

$
\begin{cases}
  \widehat a = \bar X \\
  \widehat {\sigma^2} = S^2
\end{cases} $

$
\begin{cases}
  \widehat a = \bar X \\
  \widehat {\sigma} = S
\end{cases} $

$E_\theta \bar X = \cfrac{1}{n} E \sum_{i=1}^{n} X_i = a$ - несмещённая оценка

$ E \hat{\sigma^2} = E S^2 = E \displaystyle \sum_{i = 1}^{n} (X_i - \bar{X})^2 = [ X_i - E_\theta X_i = Y_i ] = $ \
$[ E_\theta Y_i = 0 \quad D_\theta Y_i = \sigma^2 ]$ \
$\displaystyle = \frac{1}{n} E_\theta \sum_{i = 1}^{n} (Y_i - \bar{Y}) = \frac{1}{n} $
$ E\bar {Y^2} = \cfrac{1}{n} E_\theta \sum_{i=1}^{n} {(Y_i)^2} = \sigma^2 $


$E_\theta (\bar{Y} - (\bar{Y})^2) = E \bar{Y^2} - E(\bar{Y})^2 $\
$ \displaystyle E(\bar{Y^2}) = \frac{1}{n} E \sum_{i=1}^{n} Y_i^2  = \frac{1}{n} \sum_{i=1}^{n} EY_i^2 = \sigma^2 $\
$ \displaystyle E(\bar{Y})^2 = \frac{1}{n^2} E( \sum_{i=1}^{n} Y_i )^2 = \frac{1}{n} \sum_{i=1}^{n} \sum_{j=1}^{n}EY_i Y_j$\
$ EY_i Y_j = \begin{cases} \sigma^2 \quad i=j \\ 0 \quad i \neq j \end{cases} $\
$ \displaystyle E_\theta S^2 = \sigma^2 - \frac{\sigma^2}{n} = \frac{n - 1}{n} \sigma^2$\
Смещённая оценка\
$ S' = \sqrt{\frac{n}{n - 1} S^2 }$

**d)**
Доверительный интервал для параметра $a$.\
По лемме Фишера выберем генератор $ G(\vec{X}, a) = \sqrt{n - 1} \frac{\bar{X} - a}{S} \sim S_{n - 1} $\
$ \mathbb{P}_a \left( \sqrt{n - 1} \frac{\bar{X} - a}{S} \in [-x_\alpha; x_\alpha] \right) = 1 - \alpha_2 $\
$ x_\alpha : S_{n - 1}(x_\alpha) = S_{49}(x_\alpha) = 1 - \frac{\alpha_2}{2} = 0.975  $
"""

fx = 0.975
x_a = sps.t.ppf(fx, 49)

print("Квантиль x_a =", round(x_a, 3))
print("Функция распределения S_49(x_a) =", round(sps.t.cdf(x_a, 49), 3))

"""$ \displaystyle a \in \left[  \bar{X} - \frac{x_\alpha S}{\sqrt{n-  1}}; \bar{X} + \frac{x_\alpha S}{\sqrt{n-  1}} \right] = [-0.03195; 0.02517]$


---

Доверительный интеврал для параметра $\sigma^2$
По лемме Фишера выберем генератор $ \displaystyle G(\vec{X}, \sigma^2) = \frac{nS^2}{\sigma^2} \sim \chi^2_{n - 1}$\
$ \mathbb{P}_{\sigma^2} \left( \frac{nS^2}{\sigma^2} \in [-x_\alpha; x_\alpha] \right) = 1 - \alpha_2 $\
$ x_{1\alpha} : \mathcal{K}_{n - 1}(x_{1\alpha}) = \mathcal{K}_{49}(x_{1\alpha}) = \frac{\alpha_2}{2} = 0.025  $\
$ x_{2\alpha} : \mathcal{K}_{n - 1}(x_{2\alpha}) = \mathcal{K}_{49}(x_{2\alpha}) = 1 - \frac{\alpha_2}{2} = 0.975 $


"""

x_1a = sps.chi2.ppf(0.025, 49)
x_2a = sps.chi2.ppf(0.975, 49)

print("Квантиль x_1a =", round(x_1a, 3), "Квантиль x_2a =", round(x_2a, 3))
print("Функция распределения K_8(x_1a) =", round(sps.chi2.cdf(x_1a, 49), 3), "K_8(x_2a) =", round(sps.chi2.cdf(x_2a, 49), 3))

"""$ \displaystyle \sigma^2 \in \left[  \frac{n S^2}{x_{2\alpha}}; \frac{n S^2}{x_{1\alpha}} \right] = [0.00704; 0.01567]$

**e)** Основаня гипотеза $ H_0 : X_1...X_n \sim \mathcal{N}(\alpha_0, \sigma_0^2) $\
Альтернативная гипотеза $ H_А : X_1...X_n$ не распределена, как $\mathcal{N}(\alpha_0, \sigma_0^2) $

Статистика критерия Колмогорова $ \widehat{D_n} = max| F_n(x) - F_{(\alpha_0, \ \sigma_0)}(x) | $. Построим критерий Колмогорова.\
$\widehat{\varphi(\vec{X})} = \begin{cases} 0, \quad \widehat{D_n} \leq x_\alpha  \\ 1, \quad \widehat{D_n} > x_\alpha \end{cases}$, где $ x_\alpha: \mathcal{K_n}(x_\alpha) = 1 - \alpha_2 = 0.95 $\
\
Найдём $ x_a $
"""

fx = 0.95
x_a = sps.ksone.ppf(fx, 50)


print("При квантиле x_a =", round(x_a, 3))
print("K_50(x) =", round(sps.ksone.cdf(x_a, 50), 3))

"""Критерий Колмогорова\
$\widehat{\varphi(\vec{X})} = \begin{cases} 0, \quad \widehat{D_n} \leq 0.17  \\ 1, \quad \widehat{D_n} > 0.17 \end{cases}$

Найдём $D_n$
"""

def Fn(x):
  arr = [-0.2412, -0.1928, -0.1773, -0.1606, -0.1494, -0.1275, -0.1212, -0.1205, -0.1139, -0.0961, -0.0959, -0.091, -0.0873, -0.0784, -0.0745, -0.0279, -0.0266, -0.0256, -0.0192, -0.0166, -0.0059, -0.0053, -0.0047, 0.0017, 0.0018, 0.0066, 0.0124, 0.0129, 0.019, 0.0213, 0.0253, 0.0262, 0.0276, 0.0323, 0.0347, 0.0381, 0.0637, 0.0725, 0.0826, 0.0907, 0.1033, 0.1058, 0.1064, 0.1116, 0.1211, 0.1289, 0.1309, 0.1666, 0.1683, 0.1777]
  sm = 0
  for pair in arr:
    if pair >= x:
      return sm / 50
    sm += 1
  return sm / 50

x = np.arange(-1, 1, 0.001)
y = [abs(Fn(elem) - sps.laplace.cdf(elem, -0.11, 2 ** 0.5 / 0.1)) for elem in x]


print("Статистика Dn =", round(max(y), 3))

"""Т.к. $\widehat{D_n} > x_\alpha$, гипотеза $H_0$ отвергается.\
Вычислим наибольшее значение уровня значимости, на котором нет оснований отвергнуть гипотезу. Пусть $ P(\widehat{D_n} \leq x_\alpha) = 0$.\
$ \widehat{D_n} \leq x_\alpha \implies \widehat{D_n} \leq \mathcal{K_{50}^{-1}}(1 - \alpha_2) \implies \mathcal{K_{50}}(\widehat{D_n}) \leq 1 - \alpha_2 \implies \alpha_2 \leq 1 - \mathcal{K_{50}}(\widehat{D_n})$
"""

x_a = 0.495
print("Наибольший уровень значимости a_2 =", 1 - sps.ksone.cdf(x_a, 50))

"""**f)**
Таблица частот \
$ \begin{array}{|c|c|} \hline X_{(i)} & -0.2 & -0.15 & -0.1 & -0.05 & 0 & 0.05 & 0.1 & 0.15 & 0.2 \\ \hline \nu(x = X_{(i)})  & 1 & 3 & 5 & 6 & 8 & 13 & 4 & 7 & 3  \\ \hline
\end{array} $

Сгруппируем данные по интевалам.\
$ \begin{array}{|c|c|} \hline j & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9\\ \hline I_j & (-\infty, -0.2] & (-0.2, -0.15] & (-0.15, -0.1] & (-0.1, -0.05] & (-0.05, 0] & (0, 0.05] & (0.05, 0.1] & (0.1, 0.15] & (0.15, +\infty) \\ \hline \nu_j  & 1 & 3 & 5 & 6 & 8 & 13 & 4 & 7 & 3  \\ \hline
\end{array} $ \
\
$ \measuredangle$ Основную гипотезу $H_0: Ф(I_j) = F_{(\alpha_0, \sigma_0)}(I_j)$ для всех $j=1...9$ \
и альтернативную - $ H_А: {\exists j} \ Ф(I_j) \neq F_{(\alpha_0, \sigma_0)}(I_j)$, где $ j=1...9 $\
Гипотеза $ H_0 $ является более слабой по отношению к предложенной в условии, поэтому опровержение $ H_0 $ влечёт за собой опровержение и заданной гипотезы. \
\
Вычислим результаты и структурируем их в таблице \
$ \begin{array}{|c|c|} \hline I_j & \nu_j & p_{j0} & \frac{\large \left( \nu -np_{j0} \right)^2}{\large np_{j0}}\\ \hline (-\infty, -0.2] & 1 & 0.49683 & 22.882 \\ \hline (-0.2, -0.15] & 3 & 0.00176 &  96.361\\ \hline (-0.15, -0.1] & 5 & 0.00177 & 272.574\\ \hline (-0.1, -0.05] & 6 & 0.00176 & 397.179 \\ \hline (-0.05, 0] & 8 & 0.00176 & 711.361 \\ \hline (0, 0.05] & 13 & 0.00175 & 1905.516 \\ \hline (0.05, 0.1] & 4 & 0.00174 & 175.995\\ \hline (0.1, 0.15] & 7 & 0.00174 & 549.305 \\ \hline (0.15, +\infty) & 3 & 0.49089 & 18.911 \\ \hline \end{array} $ \
\
$ \chi^2 = 4150.084$\
\
Расчёты получены в результате следующей программы

"""

def CuclSum(a, g2):
  arr = [-0.2, -0.15, -0.1, -0.05, 0, 0.05, 0.1, 0.15]
  res = [0] * (len(arr) + 1)

  #Вычисление p_j0
  res[0] = sps.laplace.cdf(-0.2, a, 2 ** 0.5 / g2)

  for i in range(1, len(arr)):
    res[i] = sps.laplace.cdf(arr[i], a, 2 ** 0.5 / g2) - sps.laplace.cdf(arr[i - 1], a, 2 ** 0.5 / g2)
  res[len(arr)] = 1 - sps.laplace.cdf(0.15, a, 2 ** 0.5 / g2)
  res = [round(elem, 5) for elem in res]
  print("p_j0 =", res)
  print("Проверка результата. Сумма p_j0 =", sum(res))

  #Вычисление X^2
  v = [1, 3, 5, 6, 8, 13, 4, 7, 3]
  ans = [(v[i] - 50 * res[i]) ** 2 / (50 * res[i]) for i in range(len(v))]
  ans = [round(elem, 3) for elem in ans]
  print("Последний столбец =", ans)

  return sum(ans)

print("X^2 =", round(CuclSum(-0.11, 0.1), 3))

"""$ x_{a} : \mathcal{K}_{r-1}(x_a) = \mathcal{K}_8(x_a) = 1 - \alpha_2 = 1 - 0.02 = 0.98$"""

fx = 0.95
x_a = sps.chi2.ppf(fx, 8)

print("Квантиль x_a =", round(x_a, 3))
print("Функция распределения K_8(x_a) =", sps.chi2.cdf(x_a, 8))

"""Т.к. $\chi^2 > x_\alpha$ , то гипотеза отвергается\
Найдём наибольшее значение уровня значимости, на котором нет оснований отвергнуть гипотезу. Пусть $\mathbb{P}(\chi^2 \leq x_\alpha) = 0$\
Тогда $ \chi^2 \leq x_\alpha \implies \chi^2 \leq \mathcal{K}_8^{-1}(1 - \alpha_1) \implies \mathcal{K}_8(\chi^2) \leq 1 - \alpha_1 \implies \alpha_1 \leq 1 - \mathcal{K}_8(\chi^2)$

"""

x_a = 4150.084
print("Наибольшее значение уровня значимости =", round(1 - sps.chi2.cdf(x_a, 8), 3))

"""**g)** Проверим сложную гипотезу $ H_0 : X_1... X_n \sim F(a, \sigma^2) $ \
Альтернативой ей будет служить $ H_A : X_1 ...X_n$ не распределена, как $F(a, \sigma^2)$

Таблица частот \
$ \begin{array}{|c|c|} \hline X_{(i)} & -0.2 & -0.15 & -0.1 & -0.05 & 0 & 0.05 & 0.1 & 0.15 & 0.2 \\ \hline \nu(x = X_{(i)})  & 1 & 3 & 5 & 6 & 8 & 13 & 4 & 7 & 3  \\ \hline
\end{array} $

Сгруппируем данные по интевалам (в каждом интервале не менее 5 элементов).\
$ \begin{array}{|c|c|} \hline j & 1 & 2 & 3 & 4 & 5\\ \hline I_j & (-\infty, -0.1] &  (-0.1, -0.05] & (-0.05, 0] & (0, 0.05] & (0.05, +\infty) \\ \hline \nu_j  & 9 & 6 & 8 & 13 & 14  \\ \hline
\end{array} $ \

Т.к. гипотеза сложная, то статистикой критерия возьмём $ \tilde{\chi^2} = min_\lambda \chi^2(\lambda) = min_\lambda \displaystyle \sum_{j=1}^{5} \frac{\large \left( \nu_j -np_{j0}(\lambda) \right)^2}{\large np_{j0}(\lambda)} \underset{n \rightarrow \infty}{\implies} \chi^2_{2}$. Размерность $\chi^2$-распределения вычисляется по формуле $ r - d - 1 $, где $r$ - количество интервалов, а $d = dim(\Theta_0)$
"""

def CuclSum(args):
  arr = [-0.2, -0.15, -0.1, -0.05, 0, 0.05, 0.1, 0.15]
  res = [0] * (len(arr) + 1)

  #Вычисление p_j0
  res[0] = sps.laplace.cdf(-0.2, args[0], 2 ** 0.5 / args[1])

  for i in range(1, len(arr)):
    res[i] = sps.laplace.cdf(arr[i], args[0], 2 ** 0.5 / args[1]) - sps.laplace.cdf(arr[i - 1], args[0], 2 ** 0.5 / args[1])
  res[len(arr)] = 1 - sps.laplace.cdf(0.15, args[0], 2 ** 0.5 / args[1])

  #Вычисление X^2
  v = [1, 3, 5, 6, 8, 13, 4, 7, 3]
  ans = [(v[i] - 50 * res[i]) ** 2 / (50 * res[i]) for i in range(len(v))]

  return sum(ans)

result = spo.minimize(CuclSum, (-0.11, 0.1))

print("Значение X^2 =", round(result.fun, 5), "при значении параметров (", round(result.x[0], 5), round(result.x[1], 5), ")")

"""$ x_{a} : \mathcal{K}_{r-d-1}(x_a) = \mathcal{K}_2(x_a) = 1 - \alpha_2 = 1 - 0.05 = 0.95$"""

fx = 0.95
x_a = sps.chi2.ppf(fx, 2)

print("Квантиль x_a =", round(x_a, 3))
print("Функция распределения K_8(x_a) =", sps.chi2.cdf(x_a, 2))

"""Т.к. $\chi^2 > x_\alpha$ , то гипотеза отвергается\
Найдём наибольшее значение уровня значимости, на котором нет оснований отвергнуть гипотезу. Пусть $\mathbb{P}(\chi^2 \leq x_\alpha) = 0$\
Тогда $ \chi^2 \leq x_\alpha \implies \chi^2 \leq \mathcal{K}_2^{-1}(1 - \alpha_1) \implies \mathcal{K}_2(\chi^2) \leq 1 - \alpha_1 \implies \alpha_1 \leq 1 - \mathcal{K}_2(\chi^2)$

"""

x_a = 7.73221
print("Наибольшее значение уровня значимости =", round(1 - sps.chi2.cdf(x_a, 2), 3))

"""## Выводы

В ходе данной лабораторной работы изучено применение выборочных числовых характеристик. Разобраны принципы и освоена работа с оценкой максимального правдоподобия (ОМП) и оценкой метода моментов (ОММ). Построены доверительные интервалы, основанные на построении генераторов по лемме Фишера, и асимптотические доверительные интервалы, основанные на асимптотической нормальности оценок и информации Фишера. Изучен критерий Колмогорова для проверки гипотезы о совпадении эмпирической и теоретической функций распределения. Рассмотрены критерии Хи-квадрат для проверки гипотез о распределении данных. В результате работы также усвоены принципы построения наиболее мощного критерия для простых гипотез на основе статистики отношения правдоподобия.
"""